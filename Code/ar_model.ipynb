{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "110fe05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4b63536",
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a36800e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['A2ME', 'AC', 'AT', 'ATO', 'B2M', 'BETA_d', 'BETA_m', 'C2A', 'CF2B',\n",
      "       'CF2P', 'CTO', 'D2A', 'D2P', 'DPI2A', 'E2P', 'FC2Y', 'HIGH52', 'INV',\n",
      "       'IdioVol', 'LEV', 'ME', 'NI', 'NOA', 'OA', 'OL', 'OP', 'PCM', 'PM',\n",
      "       'PROF', 'Q', 'R12_2', 'R12_7', 'R2_1', 'R36_13', 'R60_13', 'RNA', 'ROA',\n",
      "       'ROE', 'RVAR', 'S2P', 'SGA2S', 'SPREAD', 'SUV', 'TURN', 'VAR', 'return',\n",
      "       'date', 'permno', 'monthly_update'],\n",
      "      dtype='object')\n",
      "['A2ME' 'AC' 'AT' 'ATO' 'B2M' 'BETA_d' 'BETA_m' 'C2A' 'CF2B' 'CF2P' 'CTO'\n",
      " 'D2A' 'D2P' 'DPI2A' 'E2P' 'FC2Y' 'HIGH52' 'INV' 'IdioVol' 'LEV' 'ME' 'NI'\n",
      " 'NOA' 'OA' 'OL' 'OP' 'PCM' 'PM' 'PROF' 'Q' 'R12_2' 'R12_7' 'R2_1'\n",
      " 'R36_13' 'R60_13' 'RNA' 'ROA' 'ROE' 'RVAR' 'S2P' 'SGA2S' 'SPREAD' 'SUV'\n",
      " 'TURN' 'VAR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 648/648 [03:06<00:00,  3.48it/s]\n"
     ]
    }
   ],
   "source": [
    "percentile_rank_chars, regular_chars, chars, dates,\\\n",
    "    return_panel, permnos, rts, monthly_updates = data_loading.get_data_panel(\"../Data/raw_chars_returns_df_all_dates_yearly_fb.fthr\",\n",
    "                                                            \"../Data/ff_rf.csv\",\n",
    "                                                                              computstat_data_present_filter=True,\n",
    "                                                                              financial_firm_filter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "88c7e89e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(percentile_rank_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a87e0ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "any_present = np.any(~np.isnan(percentile_rank_chars), axis=2)\n",
    "present_counts = np.sum(np.sum(np.logical_and(~np.isnan(percentile_rank_chars),\n",
    "                                             np.expand_dims(any_present, axis=2)), axis=0), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7b49b039",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordering = np.argsort(present_counts)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2d2fa3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ME' 'R2_1' 'D2P' 'SPREAD' 'RVAR' 'VAR' 'IdioVol' 'TURN' 'SUV' 'R12_7'\n",
      " 'CF2P' 'E2P' 'R12_2' 'S2P' 'B2M' 'CF2B' 'AT' 'A2ME' 'Q' 'PROF' 'PM' 'PCM'\n",
      " 'BETA_m' 'C2A' 'OL' 'ROE' 'CTO' 'ATO' 'LEV' 'NOA' 'ROA' 'RNA' 'OP' 'NI'\n",
      " 'INV' 'BETA_d' 'R36_13' 'D2A' 'FC2Y' 'SGA2S' 'OA' 'AC' 'HIGH52' 'R60_13'\n",
      " 'DPI2A']\n"
     ]
    }
   ],
   "source": [
    "print(chars[ordering])\n",
    "ordering = np.argsort(present_counts)[::-1]\n",
    "permuted_chars = percentile_rank_chars[:,:,ordering]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9ff211b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 648/648 [00:00<00:00, 691.01it/s]\n"
     ]
    }
   ],
   "source": [
    "all_data = data_loading.get_data(permuted_chars*.99 + 0.5, 30, fill_val=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "80354099",
   "metadata": {},
   "outputs": [],
   "source": [
    "import models, loss_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "00168425",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dataset = data_loading.ListDataset(all_data, batch_size=1)\n",
    "train_data_loader = DataLoader(all_dataset, batch_size=100, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "04b297a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "import time\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "85663799",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "90f4f434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'models' from '/home/selwin_p_george/CS 236 Project/Code/models.py'>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "33ee7928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch device is cuda:0\n",
      "epoch 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "095cc837fd874346ade8cd578643a776",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4535 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n",
      "torch.Size([100, 51, 5])\n",
      "torch.Size([100, 45, 5])\n",
      "torch.Size([100, 51])\n",
      "torch.Size([100, 51, 51])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3333/3088473388.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mlog_likelihood\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mlog_likelihood\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/CS 236 Project/Code/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;31m# Obtain mean vectors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0malphas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbetas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape_vectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m         \u001b[0mx_truncated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_state_dim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/CS 236 Project/Code/models.py\u001b[0m in \u001b[0;36mshape_vectors\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_diag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;31m# Compute xi*Wi + bi for each dimension in each sample.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0mbeta_dot_products\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_beta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_diag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta_dot_products\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;31m# Sigmoids of prefix sums of above to get hidden activations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = models.Beta_NADE(hidden_state_dim=6)\n",
    "\n",
    "num_epochs = 21\n",
    "eval_freq = 10\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "scheduler = MultiStepLR(optimizer, [20, 30], gamma=0.1, last_epoch=-1)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f'torch device is {device}')\n",
    "model = model.to(device)\n",
    "model.sum_matrix = model.sum_matrix.to(device)\n",
    "loss_fn = loss_functions.beta_ll_loss\n",
    "\n",
    "\n",
    "#basic training loop for local development\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_start = time.time()\n",
    "    losses = []\n",
    "    # Forward pass\n",
    "    print(f'epoch {epoch}')\n",
    "    for i, data in enumerate(tqdm(train_data_loader)):\n",
    "        model.batch_size = data[0].shape[0]\n",
    "        assert not torch.isnan(data[0]).any()\n",
    "        assert not torch.isnan(data[1]).any()\n",
    "        C_train, C_mask = data\n",
    "        C_train = C_train.squeeze(1)\n",
    "        additional_state = torch.ones(C_train.shape[0], 6)\n",
    "        model_input = torch.cat([additional_state, C_train], axis=1)\n",
    "        model_input = model_input.float().to(device)\n",
    "        \n",
    "\n",
    "        log_likelihood = model(model_input)\n",
    "        log_likelihood.mean().backward()\n",
    "\n",
    "        losses.append(log_likelihood.data.cpu().numpy())\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            optimizer.step()\n",
    "            model.zero_grad()\n",
    "            optimizer.zero_grad()       \n",
    "            \n",
    "        \n",
    "    print(f'epoch {epoch} avg loss {np.mean(losses)}')\n",
    "    print(f'epoch {epoch} took {(time.time() - epoch_start)/60.0} minutes')\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f1325e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97ed4ff4",
   "metadata": {},
   "source": [
    "# XS + LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4f7074e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import data_loading\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "068b57f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['A2ME', 'AC', 'AT', 'ATO', 'B2M', 'BETA_d', 'BETA_m', 'C2A', 'CF2B',\n",
      "       'CF2P', 'CTO', 'D2A', 'D2P', 'DPI2A', 'E2P', 'FC2Y', 'HIGH52', 'INV',\n",
      "       'IdioVol', 'LEV', 'ME', 'NI', 'NOA', 'OA', 'OL', 'OP', 'PCM', 'PM',\n",
      "       'PROF', 'Q', 'R12_2', 'R12_7', 'R2_1', 'R36_13', 'R60_13', 'RNA', 'ROA',\n",
      "       'ROE', 'RVAR', 'S2P', 'SGA2S', 'SPREAD', 'SUV', 'TURN', 'VAR', 'return',\n",
      "       'date', 'permno', 'monthly_update'],\n",
      "      dtype='object')\n",
      "['A2ME' 'AC' 'AT' 'ATO' 'B2M' 'BETA_d' 'BETA_m' 'C2A' 'CF2B' 'CF2P' 'CTO'\n",
      " 'D2A' 'D2P' 'DPI2A' 'E2P' 'FC2Y' 'HIGH52' 'INV' 'IdioVol' 'LEV' 'ME' 'NI'\n",
      " 'NOA' 'OA' 'OL' 'OP' 'PCM' 'PM' 'PROF' 'Q' 'R12_2' 'R12_7' 'R2_1'\n",
      " 'R36_13' 'R60_13' 'RNA' 'ROA' 'ROE' 'RVAR' 'S2P' 'SGA2S' 'SPREAD' 'SUV'\n",
      " 'TURN' 'VAR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 648/648 [03:05<00:00,  3.49it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "percentile_rank_chars, regular_chars, chars, dates,\\\n",
    "    return_panel, permnos, rts, monthly_updates = data_loading.get_data_panel(\"../Data/raw_chars_returns_df_all_dates_yearly_fb.fthr\",\n",
    "                                                            \"../Data/ff_rf.csv\", computstat_data_present_filter=True,\n",
    "                                                                              financial_firm_filter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8cc57d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "any_present = np.any(~np.isnan(percentile_rank_chars), axis=2)\n",
    "present_counts = np.sum(np.sum(np.logical_and(~np.isnan(percentile_rank_chars),\n",
    "                                             np.expand_dims(any_present, axis=2)), axis=0), axis=0)\n",
    "del any_present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9221b0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ME' 'R2_1' 'D2P' 'SPREAD' 'RVAR' 'VAR' 'IdioVol' 'TURN' 'SUV' 'R12_7'\n",
      " 'CF2P' 'E2P' 'R12_2' 'S2P' 'B2M' 'CF2B' 'AT' 'A2ME' 'Q' 'PROF' 'PM' 'PCM'\n",
      " 'BETA_m' 'C2A' 'OL' 'ROE' 'CTO' 'ATO' 'LEV' 'NOA' 'ROA' 'RNA' 'OP' 'NI'\n",
      " 'INV' 'BETA_d' 'R36_13' 'D2A' 'FC2Y' 'SGA2S' 'OA' 'AC' 'HIGH52' 'R60_13'\n",
      " 'DPI2A']\n"
     ]
    }
   ],
   "source": [
    "ordering = np.argsort(present_counts)[::-1]\n",
    "print(chars[ordering])\n",
    "percentile_rank_chars = percentile_rank_chars[:,:,ordering]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0b45a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_ts = np.load('../Data/gamma_ts_save.npz')['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d4323b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(648, 22630, 45)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentile_rank_chars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "293dbd82",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 400/400 [00:06<00:00, 63.96it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data = data_loading.get_data(percentile_rank_chars[:400], min_chars_present=30, fill_val=-1, \n",
    "                                   gamma_ts=gamma_ts[:400], ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b719254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'data_loading' from '/home/selwin_p_george/CS 236 Project/Code/data_loading.py'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(data_loading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ed74e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dataset = data_loading.ListDatasetWithFactors(train_data, batch_size=50)\n",
    "train_data_loader = data_loading.DataLoader(all_dataset, batch_size=10, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "137262a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import models, loss_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f513e409",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c829d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41ae6c6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 1., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 0.]], requires_grad=True) torch.Size([45, 51])\n",
      "torch device is cuda:0\n",
      "epoch 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb753949a592422faa6b210b83c1c97e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 avg lstm loss 49.45719909667969, avg ar model loss 378.0188293457031\n",
      "epoch 0 took 0.4881410797437032 minutes\n",
      "epoch 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb080b86e79543bfa1a09f4d8a227b91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 avg lstm loss -0.02864704094827175, avg ar model loss 20.501192092895508\n",
      "epoch 1 took 0.48964365720748904 minutes\n",
      "epoch 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78af36be4861465ebd90286df04450a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 avg lstm loss -0.00629857974126935, avg ar model loss 1.6311273574829102\n",
      "epoch 2 took 0.4875320355097453 minutes\n",
      "epoch 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c8167ad07414c03bccf5a2b9cee8208",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 avg lstm loss 0.009909706190228462, avg ar model loss -0.40719810128211975\n",
      "epoch 3 took 0.48851577043533323 minutes\n",
      "epoch 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b1c20eaee654674b5cd20df1a0d8c44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 avg lstm loss 0.02319185622036457, avg ar model loss -0.583076536655426\n",
      "epoch 4 took 0.48716028531392414 minutes\n",
      "epoch 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be141091c9ba42aea2f956171b68bde2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2666/474247430.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mmodel_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhidden_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = models.XSCharLSTM(input_dim=96, hidden_dim=6, num_layers=5, batch_size=10)\n",
    "ar_model = models.Beta_NADE(hidden_state_dim=6)\n",
    "\n",
    "num_epochs = 41\n",
    "eval_freq = 10\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "ar_optimizer = torch.optim.Adam(ar_model.parameters(), lr=0.01)\n",
    "\n",
    "\n",
    "scheduler = MultiStepLR(optimizer, [10, 20], gamma=0.1, last_epoch=-1)\n",
    "ar_scheduler = MultiStepLR(ar_optimizer, [10, 20], gamma=0.1, last_epoch=-1)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'torch device is {device}')\n",
    "model = model.to(device)\n",
    "ar_model = ar_model.to(device)\n",
    "loss_fn = loss_functions.beta_ll_loss\n",
    "\n",
    "\n",
    "#basic training loop for local development\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_start = time.time()\n",
    "    losses = []\n",
    "    ar_losses = []\n",
    "    # Forward pass\n",
    "    print(f'epoch {epoch}')\n",
    "    for i, data in enumerate(tqdm(train_data_loader)):\n",
    "        data, mask, ordered_mask, factors = data\n",
    "        assert not torch.isnan(data).any()\n",
    "#         print(data, mask)\n",
    "        assert not torch.logical_and(data <= 0, ~mask).any(), torch.min(data * mask)\n",
    "        \n",
    "        C_train = data.transpose_(0, 1).float().to(device)[:-1]\n",
    "        \n",
    "        C_mask = mask.float().to(device).transpose_(0, 1)[:-1]\n",
    "        C_ordered_mask = ordered_mask.float().to(device).transpose_(0, 1)[:-1]\n",
    "        \n",
    "        factors = factors.transpose_(0, 1).float().to(device)[1:]\n",
    "        \n",
    "        train_input = torch.cat([C_train, C_mask, factors], axis=2)\n",
    "        \n",
    "      \n",
    "        if train_input.shape[1] == 10:\n",
    "            alpha_pred, beta_pred, hidden_out = model(train_input)\n",
    "            loss = loss_fn(C_train[1:], alpha_pred[:-1], beta_pred[:-1], mask=C_mask[1:]).mean()\n",
    "            assert not torch.isnan(loss).any()\n",
    "            \n",
    "            loss.backward()\n",
    "            losses.append(loss.data.detach().cpu().numpy())\n",
    "            \n",
    "            model_input = torch.cat([hidden_out[:-1].detach(), C_train[1:]], axis=2)\n",
    "            batch_size, batch_length, dim = model_input.shape\n",
    "            model_input = model_input.reshape(batch_size * batch_length, dim)\n",
    "            \n",
    "            \n",
    "            \n",
    "            C_ordered_mask_reshape = C_ordered_mask[1:].reshape(batch_size * batch_length, 45)\n",
    "            C_train_reshape = C_train[1:].reshape(batch_size * batch_length, 45)\n",
    "\n",
    "            alphas_pred, betas_pred = ar_model(model_input)\n",
    "            \n",
    "            \n",
    "            ar_loss = loss_fn(C_train_reshape,\n",
    "                              alphas_pred, betas_pred, mask=C_ordered_mask_reshape,\n",
    "                             reduce_axis=1).mean()\n",
    "            ar_loss.backward()\n",
    "                        \n",
    "#             for i in range(50):\n",
    "#                 model_input = model_input[0:1]\n",
    "#                 model_input.requires_grad_(True)\n",
    "#                 alphas_pred, betas_pred = ar_model(model_input)\n",
    "#                 res = torch.sum(input_mask * alphas_pred)\n",
    "#                 print(res, res.shape, res.requires_grad)\n",
    "#                 print(model_input.shape, model_input.requires_grad)\n",
    "#                 input_mask = torch.zeros_like(alphas_pred).to(device)\n",
    "#                 input_mask[0,i] = 1\n",
    "#                 print(i, torch.autograd.grad(res, model_input, create_graph=True))\n",
    "            \n",
    "            ar_losses.append(ar_loss.data.detach().cpu().numpy())\n",
    "            \n",
    "            optimizer.step()\n",
    "            model.zero_grad()\n",
    "            optimizer.zero_grad()       \n",
    "\n",
    "            ar_optimizer.step()\n",
    "            ar_model.zero_grad()\n",
    "            ar_optimizer.zero_grad()\n",
    "\n",
    "    print(f'epoch {epoch} avg lstm loss {np.mean(losses)}, avg ar model loss {np.mean(ar_losses)}')\n",
    "    print(f'epoch {epoch} took {(time.time() - epoch_start)/60.0} minutes')\n",
    "    scheduler.step()\n",
    "    ar_scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b70ddfc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9419dfb72784fa7895bd1fded619466",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[('ME', 0.016994426),\n",
       " ('R2_1', 0.018275818),\n",
       " ('D2P', 0.011704876),\n",
       " ('SPREAD', 0.010778561),\n",
       " ('RVAR', 0.0145637365),\n",
       " ('VAR', 0.013189538),\n",
       " ('IdioVol', 0.01024529),\n",
       " ('TURN', 0.010119821),\n",
       " ('SUV', 0.008239745),\n",
       " ('R12_7', 0.014688572),\n",
       " ('CF2P', 0.012033416),\n",
       " ('E2P', 0.011507633),\n",
       " ('R12_2', 0.014200185),\n",
       " ('S2P', 0.015179531),\n",
       " ('B2M', 0.021411572),\n",
       " ('CF2B', 0.014513005),\n",
       " ('AT', 0.017653378),\n",
       " ('A2ME', 0.015375111),\n",
       " ('Q', 0.014285593),\n",
       " ('PROF', 0.00805442),\n",
       " ('PM', 0.010016139),\n",
       " ('PCM', 0.00839753),\n",
       " ('BETA_m', 0.014789646),\n",
       " ('C2A', 0.01997428),\n",
       " ('OL', 0.021216303),\n",
       " ('ROE', 0.007967139),\n",
       " ('CTO', 0.01942396),\n",
       " ('ATO', 0.011658184),\n",
       " ('LEV', 0.011625119),\n",
       " ('NOA', 0.02127807),\n",
       " ('ROA', 0.01048511),\n",
       " ('RNA', 0.007962812),\n",
       " ('OP', 0.010118417),\n",
       " ('NI', 0.01209986),\n",
       " ('INV', 0.008693303),\n",
       " ('BETA_d', 0.018214818),\n",
       " ('R36_13', 0.01655251),\n",
       " ('D2A', 0.01572101),\n",
       " ('FC2Y', 0.009094659),\n",
       " ('SGA2S', 0.009705063),\n",
       " ('OA', 0.013145341),\n",
       " ('AC', 0.014749289),\n",
       " ('HIGH52', 0.014553352),\n",
       " ('R60_13', 0.015131253),\n",
       " ('DPI2A', 0.24402978)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = []\n",
    "gts = []\n",
    "train_masks = []\n",
    "for i, data in enumerate(tqdm(train_data_loader)):\n",
    "    data, mask, ordered_mask, factors = data\n",
    "    assert not torch.isnan(data).any()\n",
    "#         print(data, mask)\n",
    "    assert not torch.logical_and(data <= 0, ~mask).any(), torch.min(data * mask)\n",
    "\n",
    "    C_train = data.transpose_(0, 1).float().to(device)[:-1]\n",
    "        \n",
    "    C_mask = mask.float().to(device).transpose_(0, 1)[:-1]\n",
    "    C_ordered_mask = ordered_mask.float().to(device).transpose_(0, 1)[:-1]\n",
    "\n",
    "    factors = factors.transpose_(0, 1).float().to(device)[1:]\n",
    "\n",
    "    train_input = torch.cat([C_train, C_mask, factors], axis=2)\n",
    "\n",
    "\n",
    "    if train_input.shape[1] == 10:\n",
    "        alpha_pred, beta_pred, hidden_out = model(train_input)\n",
    "\n",
    "        model_input = torch.cat([hidden_out[:-1].detach(), C_train[1:]], axis=2)\n",
    "        batch_size, batch_length, dim = model_input.shape\n",
    "        model_input = model_input.reshape(batch_size * batch_length, dim)\n",
    "\n",
    "        C_ordered_mask_reshape = C_ordered_mask[1:].reshape(batch_size * batch_length, 45)\n",
    "        C_train_reshape = C_train[1:].reshape(batch_size * batch_length, 45)\n",
    "\n",
    "        alphas_pred, betas_pred = ar_model(model_input)\n",
    "        pred = alphas_pred / (alphas_pred + betas_pred)\n",
    "        preds.append(pred.detach().cpu().numpy())\n",
    "        gts.append(C_train_reshape.detach().cpu().numpy())\n",
    "        train_masks.append(C_ordered_mask_reshape.detach().cpu().numpy())\n",
    "\n",
    "preds = np.concatenate(preds, axis=0)\n",
    "gts = np.concatenate(gts, axis=0)\n",
    "train_masks = np.concatenate(train_masks, axis=0)\n",
    "gts[train_masks == 1] = np.nan\n",
    "mse = np.nanmean((preds - gts)**2, axis=0)\n",
    "list(zip(chars[ordering], np.sqrt(mse)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea1308b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "gts = []\n",
    "train_masks = []\n",
    "for i, data in enumerate(tqdm(train_data_loader)):\n",
    "    data, mask, ordered_mask, factors = data\n",
    "    assert not torch.isnan(data).any()\n",
    "#         assert not (data <= 0).any(), torch.min(data)\n",
    "#         print(data.shape)\n",
    "    C_train = data.transpose_(0, 1).float().to(device)[:-1]\n",
    "        \n",
    "    C_mask = mask.float().to(device).transpose_(0, 1)[:-1]\n",
    "    C_ordered_mask = ordered_mask.float().to(device).transpose_(0, 1)[:-1]\n",
    "\n",
    "    factors = factors.transpose_(0, 1).float().to(device)[1:]\n",
    "\n",
    "    train_input = torch.cat([C_train, C_mask, factors], axis=2)       \n",
    "    if train_input.shape[1] == 10:\n",
    "        alpha_pred, beta_pred,_ = model(train_input)\n",
    "\n",
    "        pred = alpha_pred / (alpha_pred + beta_pred)\n",
    "        preds.append(pred.detach().cpu().numpy())\n",
    "        gts.append(C_train.detach().cpu().numpy())\n",
    "        train_masks.append(C_mask.detach().cpu().numpy())\n",
    "\n",
    "preds = np.concatenate(preds, axis=0)\n",
    "gts = np.concatenate(gts, axis=0)\n",
    "train_masks = np.concatenate(train_masks, axis=0)\n",
    "gts[train_masks == 1] = np.nan\n",
    "\n",
    "mse = np.nanmean((preds - gts)**2, axis=(0,1))\n",
    "list(zip(chars[ordering], np.sqrt(mse))), np.mean(np.sqrt(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ba025247",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 200/200 [00:03<00:00, 52.36it/s]\n"
     ]
    }
   ],
   "source": [
    "val_data = data_loading.get_data(percentile_rank_chars[400:600], min_chars_present=30, fill_val=-1, \n",
    "                                   gamma_ts=gamma_ts[400:600], ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "98f2b75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dataset = data_loading.ListDatasetWithFactors(val_data, batch_size=50)\n",
    "train_data_loader = data_loading.DataLoader(all_dataset, batch_size=10, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c0f68b8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5c16ddc4bbf457f9ca77c514f20a619",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/475 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[('ME', 0.009420439),\n",
       " ('R2_1', 0.015046226),\n",
       " ('D2P', 0.012610359),\n",
       " ('SPREAD', 0.0109960325),\n",
       " ('RVAR', 0.022174569),\n",
       " ('VAR', 0.010580117),\n",
       " ('IdioVol', 0.009986096),\n",
       " ('TURN', 0.006420104),\n",
       " ('SUV', 0.0069246166),\n",
       " ('R12_7', 0.009092975),\n",
       " ('CF2P', 0.0066264374),\n",
       " ('E2P', 0.011351572),\n",
       " ('R12_2', 0.005376908),\n",
       " ('S2P', 0.0128406165),\n",
       " ('B2M', 0.006662936),\n",
       " ('CF2B', 0.008431717),\n",
       " ('AT', 0.006823305),\n",
       " ('A2ME', 0.019575287),\n",
       " ('Q', 0.01590447),\n",
       " ('PROF', 0.005817745),\n",
       " ('PM', 0.006029416),\n",
       " ('PCM', 0.014015055),\n",
       " ('BETA_m', 0.008359386),\n",
       " ('C2A', 0.00525353),\n",
       " ('OL', 0.013458848),\n",
       " ('ROE', 0.005667036),\n",
       " ('CTO', 0.009215627),\n",
       " ('ATO', 0.0064174696),\n",
       " ('LEV', 0.014428355),\n",
       " ('NOA', 0.011127448),\n",
       " ('ROA', 0.011565131),\n",
       " ('RNA', 0.010131157),\n",
       " ('OP', 0.0092309415),\n",
       " ('NI', 0.0113786645),\n",
       " ('INV', 0.014147015),\n",
       " ('BETA_d', 0.0074790884),\n",
       " ('R36_13', 0.010916909),\n",
       " ('D2A', 0.013918674),\n",
       " ('FC2Y', 0.0090912925),\n",
       " ('SGA2S', 0.015098919),\n",
       " ('OA', 0.013236991),\n",
       " ('AC', 0.0057610646),\n",
       " ('HIGH52', 0.009743413),\n",
       " ('R60_13', 0.006927686),\n",
       " ('DPI2A', 0.26077962)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = []\n",
    "gts = []\n",
    "train_masks = []\n",
    "for i, data in enumerate(tqdm(train_data_loader)):\n",
    "    data, mask, ordered_mask, factors = data\n",
    "    assert not torch.isnan(data).any()\n",
    "#         print(data, mask)\n",
    "    assert not torch.logical_and(data <= 0, ~mask).any(), torch.min(data * mask)\n",
    "\n",
    "    C_train = data.transpose_(0, 1).float().to(device)[:-1]\n",
    "        \n",
    "    C_mask = mask.float().to(device).transpose_(0, 1)[:-1]\n",
    "    C_ordered_mask = ordered_mask.float().to(device).transpose_(0, 1)[:-1]\n",
    "\n",
    "    factors = factors.transpose_(0, 1).float().to(device)[1:]\n",
    "\n",
    "    train_input = torch.cat([C_train, C_mask, factors], axis=2)\n",
    "\n",
    "\n",
    "    if train_input.shape[1] == 10:\n",
    "        alpha_pred, beta_pred, hidden_out = model(train_input)\n",
    "\n",
    "        model_input = torch.cat([hidden_out[:-1].detach(), C_train[1:]], axis=2)\n",
    "        batch_size, batch_length, dim = model_input.shape\n",
    "        model_input = model_input.reshape(batch_size * batch_length, dim)\n",
    "\n",
    "        C_ordered_mask_reshape = C_ordered_mask[1:].reshape(batch_size * batch_length, 45)\n",
    "        C_train_reshape = C_train[1:].reshape(batch_size * batch_length, 45)\n",
    "\n",
    "        alphas_pred, betas_pred = ar_model(model_input)\n",
    "        pred = alphas_pred / (alphas_pred + betas_pred)\n",
    "        preds.append(pred.detach().cpu().numpy())\n",
    "        gts.append(C_train_reshape.detach().cpu().numpy())\n",
    "        train_masks.append(C_ordered_mask_reshape.detach().cpu().numpy())\n",
    "\n",
    "preds = np.concatenate(preds, axis=0)\n",
    "gts = np.concatenate(gts, axis=0)\n",
    "train_masks = np.concatenate(train_masks, axis=0)\n",
    "gts[train_masks == 1] = np.nan\n",
    "mse = np.nanmean((preds - gts)**2, axis=0)\n",
    "list(zip(chars[ordering], np.sqrt(mse)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f59f4bd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88a81ac1eceb4ab2bf6724b01d7fb3e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/475 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = []\n",
    "gts = []\n",
    "train_masks = []\n",
    "for i, data in enumerate(tqdm(train_data_loader)):\n",
    "    data, mask, ordered_mask, factors = data\n",
    "    assert not torch.isnan(data).any()\n",
    "#         assert not (data <= 0).any(), torch.min(data)\n",
    "#         print(data.shape)\n",
    "    C_train = data.transpose_(0, 1).float().to(device)[:-1]\n",
    "        \n",
    "    C_mask = mask.float().to(device).transpose_(0, 1)[:-1]\n",
    "    C_ordered_mask = ordered_mask.float().to(device).transpose_(0, 1)[:-1]\n",
    "\n",
    "    factors = factors.transpose_(0, 1).float().to(device)[1:]\n",
    "\n",
    "    train_input = torch.cat([C_train, C_mask, factors], axis=2)       \n",
    "    if train_input.shape[1] == 10:\n",
    "        alpha_pred, beta_pred,_ = model(train_input)\n",
    "\n",
    "        pred = alpha_pred / (alpha_pred + beta_pred)\n",
    "        preds.append(pred.detach().cpu().numpy())\n",
    "        gts.append(C_train.detach().cpu().numpy())\n",
    "        train_masks.append(C_mask.detach().cpu().numpy())\n",
    "\n",
    "preds = np.concatenate(preds, axis=0)\n",
    "gts = np.concatenate(gts, axis=0)\n",
    "train_masks = np.concatenate(train_masks, axis=0)\n",
    "gts[train_masks == 1] = np.nan\n",
    "\n",
    "mse = np.nanmean((preds - gts)**2, axis=(0,1))\n",
    "list(zip(chars[ordering], np.sqrt(mse))), np.mean(np.sqrt(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dfe54c61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('ME', 0.2882925),\n",
       "  ('R2_1', 0.2861115),\n",
       "  ('D2P', 0.29338998),\n",
       "  ('SPREAD', 0.28889006),\n",
       "  ('RVAR', 0.27280915),\n",
       "  ('VAR', 0.2739712),\n",
       "  ('IdioVol', 0.27303356),\n",
       "  ('TURN', 0.28869623),\n",
       "  ('SUV', 0.2847902),\n",
       "  ('R12_7', 0.28743878),\n",
       "  ('CF2P', 0.28312084),\n",
       "  ('E2P', 0.28100437),\n",
       "  ('R12_2', 0.28635156),\n",
       "  ('S2P', 0.28011435),\n",
       "  ('B2M', 0.28301242),\n",
       "  ('CF2B', 0.28014743),\n",
       "  ('AT', 0.28357416),\n",
       "  ('A2ME', 0.2842634),\n",
       "  ('Q', 0.2837084),\n",
       "  ('PROF', 0.28037572),\n",
       "  ('PM', 0.27831548),\n",
       "  ('PCM', 0.28394076),\n",
       "  ('BETA_m', 0.29008412),\n",
       "  ('C2A', 0.28667018),\n",
       "  ('OL', 0.28245237),\n",
       "  ('ROE', 0.28184167),\n",
       "  ('CTO', 0.28100416),\n",
       "  ('ATO', 0.28132066),\n",
       "  ('LEV', 0.28749672),\n",
       "  ('NOA', 0.2832554),\n",
       "  ('ROA', 0.2837932),\n",
       "  ('RNA', 0.28129646),\n",
       "  ('OP', 0.27933842),\n",
       "  ('NI', 0.28610462),\n",
       "  ('INV', 0.28695932),\n",
       "  ('BETA_d', 0.29208195),\n",
       "  ('R36_13', 0.29069445),\n",
       "  ('D2A', 0.28611156),\n",
       "  ('FC2Y', 0.2788018),\n",
       "  ('SGA2S', 0.2795629),\n",
       "  ('OA', 0.2829811),\n",
       "  ('AC', 0.28346103),\n",
       "  ('HIGH52', 0.28267318),\n",
       "  ('R60_13', 0.29099247),\n",
       "  ('DPI2A', 0.28698972)],\n",
       " 0.2838071)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(chars[ordering], np.sqrt(mse))), np.mean(np.sqrt(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31de902",
   "metadata": {},
   "source": [
    "# Optimize Jointly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0190af3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 400/400 [00:06<00:00, 64.01it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data = data_loading.get_data(percentile_rank_chars[:400], min_chars_present=30, fill_val=-1, \n",
    "                                   gamma_ts=gamma_ts[:400], ordered=True)\n",
    "all_dataset = data_loading.ListDatasetWithFactors(train_data, batch_size=50)\n",
    "train_data_loader = data_loading.DataLoader(all_dataset, batch_size=10, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e49a4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch device is cuda:0\n",
      "epoch 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb2fcaaa7d7f42bfaf798308aebac73d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 avg lstm loss 0.09326416999101639, avg ar model loss -41.55487060546875\n",
      "epoch 0 took 0.4808860143025716 minutes\n",
      "epoch 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3df3cbc32c434304bff13a5ef77f97fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 avg lstm loss 0.07046534866094589, avg ar model loss -82.2635726928711\n",
      "epoch 1 took 0.4803778290748596 minutes\n",
      "epoch 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "251288972c3e4790825de46f5b822407",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 avg lstm loss 0.046286582946777344, avg ar model loss -90.7486801147461\n",
      "epoch 2 took 0.4815201282501221 minutes\n",
      "epoch 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9577653e70a4ca2a605bcca2113af37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 avg lstm loss 0.045342739671468735, avg ar model loss -93.5308837890625\n",
      "epoch 3 took 0.48138664960861205 minutes\n",
      "epoch 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcd2d875bbc04b9984fdf08451820bfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 avg lstm loss -0.08833754062652588, avg ar model loss -94.96382141113281\n",
      "epoch 4 took 0.4807014028231303 minutes\n",
      "epoch 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30d47257c15b4ceea57fb5d2b4a9ba8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 avg lstm loss -0.26438161730766296, avg ar model loss -96.46426391601562\n",
      "epoch 5 took 0.481057866414388 minutes\n",
      "epoch 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55c507ee03414680b36fcf0b77bbe0d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 avg lstm loss -2.225677967071533, avg ar model loss -95.8322982788086\n",
      "epoch 6 took 0.4815356810887655 minutes\n",
      "epoch 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99404e1c7a1e4829ad121c19a3485606",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7 avg lstm loss -4.553793907165527, avg ar model loss -96.88137817382812\n",
      "epoch 7 took 0.481248672803243 minutes\n",
      "epoch 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd90a10eb2db4e84bbe9ff2e896c264a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8 avg lstm loss -5.184929847717285, avg ar model loss -97.40753936767578\n",
      "epoch 8 took 0.4807138522466024 minutes\n",
      "epoch 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7f11382113f4f3c875ef5f5a1625c03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9 avg lstm loss -5.556225776672363, avg ar model loss -97.7452163696289\n",
      "epoch 9 took 0.4808824578921 minutes\n",
      "epoch 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60dc7b8d41a3436ba89c07d05a98fdd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10 avg lstm loss -6.005099773406982, avg ar model loss -98.01300048828125\n",
      "epoch 10 took 0.4822430690129598 minutes\n",
      "epoch 11\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28501dae129c48f892e1456882eeab9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11 avg lstm loss -7.105661869049072, avg ar model loss -98.1661605834961\n",
      "epoch 11 took 0.48140735228856407 minutes\n",
      "epoch 12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d04510e317846cc8bc18a07222f53d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12 avg lstm loss -7.9474639892578125, avg ar model loss -98.32150268554688\n",
      "epoch 12 took 0.4821423411369324 minutes\n",
      "epoch 13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "585f8c7889054cf19827f793f2e98327",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13 avg lstm loss -8.597996711730957, avg ar model loss -98.44963073730469\n",
      "epoch 13 took 0.48235191504160563 minutes\n",
      "epoch 14\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7faf76288bf4c11a208f157a3faa626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14 avg lstm loss -8.934721946716309, avg ar model loss -98.55731964111328\n",
      "epoch 14 took 0.48282740513483685 minutes\n",
      "epoch 15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ca687c76eb947cc8bab3345afe80f60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15 avg lstm loss -9.179129600524902, avg ar model loss -98.66886138916016\n",
      "epoch 15 took 0.4796007434527079 minutes\n",
      "epoch 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f8fbdda6fcd4fe499d8f7a77d72baa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16 avg lstm loss -9.333342552185059, avg ar model loss -98.76403045654297\n",
      "epoch 16 took 0.4813433329264323 minutes\n",
      "epoch 17\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f953825bbde1443682dd7c2c937ba7ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2666/3106181493.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mC_train_reshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mC_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m45\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0malphas_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbetas_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             ar_loss = loss_fn(C_train_reshape,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/CS 236 Project/Code/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;31m# Obtain mean vectors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0malphas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbetas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape_vectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0malphas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbetas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/CS 236 Project/Code/models.py\u001b[0m in \u001b[0;36mshape_vectors\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshape_vectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;31m# Expand each sample as a diagonal matrix.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0mx_diag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_j\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx_j\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0;31m# Compute xi*Wi + bi for each dimension in each sample.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mbeta_dot_products\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_beta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_diag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/CS 236 Project/Code/models.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshape_vectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;31m# Expand each sample as a diagonal matrix.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0mx_diag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_j\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx_j\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0;31m# Compute xi*Wi + bi for each dimension in each sample.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mbeta_dot_products\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_beta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_diag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# model = models.XSCharLSTM(input_dim=96, hiddin_dim=15, num_layers=2, batch_size=10)\n",
    "# ar_model = models.Beta_NADE(hidden_state_dim=6)\n",
    "\n",
    "num_epochs = 41\n",
    "eval_freq = 10\n",
    "\n",
    "optimizer = torch.optim.Adam(list(model.parameters()) + list(ar_model.parameters()), lr=0.01)\n",
    "\n",
    "\n",
    "scheduler = MultiStepLR(optimizer, [20, 35], gamma=0.1, last_epoch=-1)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'torch device is {device}')\n",
    "model = model.to(device)\n",
    "ar_model = ar_model.to(device)\n",
    "loss_fn = loss_functions.beta_ll_loss\n",
    "\n",
    "\n",
    "#basic training loop for local development\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_start = time.time()\n",
    "    losses = []\n",
    "    ar_losses = []\n",
    "    # Forward pass\n",
    "    print(f'epoch {epoch}')\n",
    "    for i, data in enumerate(tqdm(train_data_loader)):\n",
    "        data, mask, ordered_mask, factors = data\n",
    "        assert not torch.isnan(data).any()\n",
    "#         print(data, mask)\n",
    "        assert not torch.logical_and(data <= 0, ~mask).any(), torch.min(data * mask)\n",
    "        \n",
    "        C_train = data.transpose_(0, 1).float().to(device)[:-1]\n",
    "        \n",
    "        C_mask = mask.float().to(device).transpose_(0, 1)[:-1]\n",
    "        C_ordered_mask = ordered_mask.float().to(device).transpose_(0, 1)[:-1]\n",
    "        \n",
    "        factors = factors.transpose_(0, 1).float().to(device)[1:]\n",
    "        \n",
    "        train_input = torch.cat([C_train, C_mask, factors], axis=2)\n",
    "        \n",
    "      \n",
    "        if train_input.shape[1] == 10:\n",
    "            alpha_pred, beta_pred, hidden_out = model(train_input)\n",
    "            loss = loss_fn(C_train[1:], alpha_pred[:-1], beta_pred[:-1], mask=C_mask[1:]).mean()\n",
    "            assert not torch.isnan(loss).any()\n",
    "            \n",
    "#             loss.backward()\n",
    "            losses.append(loss.data.detach().cpu().numpy())\n",
    "            \n",
    "#             print(hidden_out.shape, C_train.shape)\n",
    "            model_input = torch.cat([hidden_out[:-1].detach(), C_train[1:]], axis=2)\n",
    "            batch_size, batch_length, dim = model_input.shape\n",
    "            model_input = model_input.reshape(batch_size * batch_length, dim)\n",
    "            \n",
    "            C_ordered_mask_reshape = C_ordered_mask[1:].reshape(batch_size * batch_length, 45)\n",
    "            C_train_reshape = C_train[1:].reshape(batch_size * batch_length, 45)\n",
    "\n",
    "            alphas_pred, betas_pred = ar_model(model_input)\n",
    "            \n",
    "            ar_loss = loss_fn(C_train_reshape,\n",
    "                              alphas_pred, betas_pred, mask=C_ordered_mask_reshape,\n",
    "                             reduce_axis=1).mean()\n",
    "            \n",
    "            net_loss = ar_loss + loss\n",
    "            net_loss.backward()\n",
    "            ar_losses.append(ar_loss.data.detach().cpu().numpy())\n",
    "            \n",
    "#             if i % 100 == 0:\n",
    "#                 print(loss)\n",
    "#                 print(ar_loss)\n",
    "            \n",
    "#             if i % 10 == 0:\n",
    "    #             torch.nn.utils.clip_grad_norm_(model.parameters(), 50)\n",
    "            optimizer.step()\n",
    "            model.zero_grad()\n",
    "            optimizer.zero_grad()       \n",
    "                \n",
    "\n",
    "    print(f'epoch {epoch} avg lstm loss {np.mean(losses)}, avg ar model loss {np.mean(ar_losses)}')\n",
    "    print(f'epoch {epoch} took {(time.time() - epoch_start)/60.0} minutes')\n",
    "    scheduler.step()\n",
    "    ar_scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72928568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9272567d5de24698a6c0ae58dd427782",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[('ME', 0.007981713),\n",
       " ('R2_1', 0.006885205),\n",
       " ('D2P', 0.0118199615),\n",
       " ('SPREAD', 0.0062841927),\n",
       " ('RVAR', 0.0074379155),\n",
       " ('VAR', 0.007371009),\n",
       " ('IdioVol', 0.0070895418),\n",
       " ('TURN', 0.005612313),\n",
       " ('SUV', 0.006341484),\n",
       " ('R12_7', 0.007576596),\n",
       " ('CF2P', 0.009736982),\n",
       " ('E2P', 0.008215547),\n",
       " ('R12_2', 0.0061396547),\n",
       " ('S2P', 0.012034022),\n",
       " ('B2M', 0.015507225),\n",
       " ('CF2B', 0.0064073396),\n",
       " ('AT', 0.014131421),\n",
       " ('A2ME', 0.011805018),\n",
       " ('Q', 0.007177227),\n",
       " ('PROF', 0.007877403),\n",
       " ('PM', 0.009971296),\n",
       " ('PCM', 0.007381135),\n",
       " ('BETA_m', 0.011924914),\n",
       " ('C2A', 0.0092319865),\n",
       " ('OL', 0.01362965),\n",
       " ('ROE', 0.0068265377),\n",
       " ('CTO', 0.008582859),\n",
       " ('ATO', 0.009116479),\n",
       " ('LEV', 0.016384605),\n",
       " ('NOA', 0.0073727127),\n",
       " ('ROA', 0.007902001),\n",
       " ('RNA', 0.0076342486),\n",
       " ('OP', 0.0069478597),\n",
       " ('NI', 0.009699914),\n",
       " ('INV', 0.0058400277),\n",
       " ('BETA_d', 0.010533223),\n",
       " ('R36_13', 0.0060214708),\n",
       " ('D2A', 0.008907987),\n",
       " ('FC2Y', 0.019286048),\n",
       " ('SGA2S', 0.014578915),\n",
       " ('OA', 0.0082325665),\n",
       " ('AC', 0.0076015987),\n",
       " ('HIGH52', 0.006189481),\n",
       " ('R60_13', 0.010328672),\n",
       " ('DPI2A', 0.0076105325)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = []\n",
    "gts = []\n",
    "train_masks = []\n",
    "for i, data in enumerate(tqdm(train_data_loader)):\n",
    "    data, mask, ordered_mask, factors = data\n",
    "    assert not torch.isnan(data).any()\n",
    "#         print(data, mask)\n",
    "    assert not torch.logical_and(data <= 0, ~mask).any(), torch.min(data * mask)\n",
    "\n",
    "    C_train = data.transpose_(0, 1).float().to(device)[:-1]\n",
    "        \n",
    "    C_mask = mask.float().to(device).transpose_(0, 1)[:-1]\n",
    "    C_ordered_mask = ordered_mask.float().to(device).transpose_(0, 1)[:-1]\n",
    "\n",
    "    factors = factors.transpose_(0, 1).float().to(device)[1:]\n",
    "\n",
    "    train_input = torch.cat([C_train, C_mask, factors], axis=2)\n",
    "\n",
    "\n",
    "    if train_input.shape[1] == 10:\n",
    "        alpha_pred, beta_pred, hidden_out = model(train_input)\n",
    "\n",
    "        model_input = torch.cat([hidden_out[:-1].detach(), C_train[1:]], axis=2)\n",
    "        batch_size, batch_length, dim = model_input.shape\n",
    "        model_input = model_input.reshape(batch_size * batch_length, dim)\n",
    "\n",
    "        C_mask_reshape = C_ordered_mask[1:].reshape(batch_size * batch_length, 45)\n",
    "        C_ordered_mask_reshape = C_ordered_mask[1:].reshape(batch_size * batch_length, 45)\n",
    "        C_train_reshape = C_train[1:].reshape(batch_size * batch_length, 45)\n",
    "\n",
    "        alphas_pred, betas_pred = ar_model(model_input)\n",
    "        pred = alphas_pred / (alphas_pred + betas_pred)\n",
    "        preds.append(pred.detach().cpu().numpy())\n",
    "        gts.append(C_train_reshape.detach().cpu().numpy())\n",
    "        train_masks.append(C_ordered_mask_reshape.detach().cpu().numpy())\n",
    "\n",
    "preds = np.concatenate(preds, axis=0)\n",
    "gts = np.concatenate(gts, axis=0)\n",
    "train_masks = np.concatenate(train_masks, axis=0)\n",
    "gts[train_masks == 1] = np.nan\n",
    "mse = np.nanmean((preds - gts)**2, axis=0)\n",
    "list(zip(chars[ordering], np.sqrt(mse)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d34e7f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b10d56a010ce47628cfaca6d94f54ab7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "([('ME', 0.20989154),\n",
       "  ('R2_1', 0.27405956),\n",
       "  ('D2P', 0.24115486),\n",
       "  ('SPREAD', 0.1802615),\n",
       "  ('RVAR', 0.12719882),\n",
       "  ('VAR', 0.13032171),\n",
       "  ('IdioVol', 0.13907516),\n",
       "  ('TURN', 0.26824632),\n",
       "  ('SUV', 0.2846091),\n",
       "  ('R12_7', 0.26243508),\n",
       "  ('CF2P', 0.236937),\n",
       "  ('E2P', 0.25259954),\n",
       "  ('R12_2', 0.25672165),\n",
       "  ('S2P', 0.20594539),\n",
       "  ('B2M', 0.18664782),\n",
       "  ('CF2B', 0.2703901),\n",
       "  ('AT', 0.19596305),\n",
       "  ('A2ME', 0.07628629),\n",
       "  ('Q', 0.070202984),\n",
       "  ('PROF', 0.27266416),\n",
       "  ('PM', 0.23614624),\n",
       "  ('PCM', 0.2677706),\n",
       "  ('BETA_m', 0.2596293),\n",
       "  ('C2A', 0.26492605),\n",
       "  ('OL', 0.27337477),\n",
       "  ('ROE', 0.24692792),\n",
       "  ('CTO', 0.27201715),\n",
       "  ('ATO', 0.2701464),\n",
       "  ('LEV', 0.23253366),\n",
       "  ('NOA', 0.2752484),\n",
       "  ('ROA', 0.22761074),\n",
       "  ('RNA', 0.23910455),\n",
       "  ('OP', 0.25431982),\n",
       "  ('NI', 0.28108224),\n",
       "  ('INV', 0.26003313),\n",
       "  ('BETA_d', 0.2605864),\n",
       "  ('R36_13', 0.26294377),\n",
       "  ('D2A', 0.2687445),\n",
       "  ('FC2Y', 0.25788352),\n",
       "  ('SGA2S', 0.25555232),\n",
       "  ('OA', 0.2774026),\n",
       "  ('AC', 0.2780474),\n",
       "  ('HIGH52', 0.2423506),\n",
       "  ('R60_13', 0.25558695),\n",
       "  ('DPI2A', 0.27742535)],\n",
       " 0.23642237)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = []\n",
    "gts = []\n",
    "train_masks = []\n",
    "for i, data in enumerate(tqdm(train_data_loader)):\n",
    "    data, mask, ordered_mask, factors = data\n",
    "    assert not torch.isnan(data).any()\n",
    "#         assert not (data <= 0).any(), torch.min(data)\n",
    "#         print(data.shape)\n",
    "    C_train = data.transpose_(0, 1).float().to(device)[:-1]\n",
    "        \n",
    "    C_mask = mask.float().to(device).transpose_(0, 1)[:-1]\n",
    "    C_ordered_mask = ordered_mask.float().to(device).transpose_(0, 1)[:-1]\n",
    "\n",
    "    factors = factors.transpose_(0, 1).float().to(device)[1:]\n",
    "\n",
    "    train_input = torch.cat([C_train, C_mask, factors], axis=2)       \n",
    "    if train_input.shape[1] == 10:\n",
    "        alpha_pred, beta_pred,_ = model(train_input)\n",
    "\n",
    "        pred = alpha_pred / (alpha_pred + beta_pred)\n",
    "        preds.append(pred.detach().cpu().numpy())\n",
    "        gts.append(C_train.detach().cpu().numpy())\n",
    "        train_masks.append(C_mask.detach().cpu().numpy())\n",
    "\n",
    "preds = np.concatenate(preds, axis=0)\n",
    "gts = np.concatenate(gts, axis=0)\n",
    "train_masks = np.concatenate(train_masks, axis=0)\n",
    "gts[train_masks == 1] = np.nan\n",
    "\n",
    "mse = np.nanmean((preds - gts)**2, axis=(0,1))\n",
    "list(zip(chars[ordering], np.sqrt(mse))), np.mean(np.sqrt(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "edb72328",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 200/200 [00:04<00:00, 46.74it/s]\n"
     ]
    }
   ],
   "source": [
    "val_data = data_loading.get_data(percentile_rank_chars[400:600], min_chars_present=30, fill_val=-1, \n",
    "                                   gamma_ts=gamma_ts[400:600], ordered=True)\n",
    "all_dataset = data_loading.ListDatasetWithFactors(val_data, batch_size=50)\n",
    "train_data_loader = data_loading.DataLoader(all_dataset, batch_size=10, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "487ae3e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56d8a710c3064470a50e6e91ddafb73f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/475 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[('ME', 0.007650777),\n",
       " ('R2_1', 0.0068526855),\n",
       " ('D2P', 0.011803265),\n",
       " ('SPREAD', 0.0063405163),\n",
       " ('RVAR', 0.008038786),\n",
       " ('VAR', 0.007911834),\n",
       " ('IdioVol', 0.007604321),\n",
       " ('TURN', 0.0056969062),\n",
       " ('SUV', 0.006390973),\n",
       " ('R12_7', 0.0075663207),\n",
       " ('CF2P', 0.010530385),\n",
       " ('E2P', 0.00801664),\n",
       " ('R12_2', 0.006361285),\n",
       " ('S2P', 0.011934971),\n",
       " ('B2M', 0.015291166),\n",
       " ('CF2B', 0.0063031167),\n",
       " ('AT', 0.014312125),\n",
       " ('A2ME', 0.011729534),\n",
       " ('Q', 0.0074521448),\n",
       " ('PROF', 0.007867415),\n",
       " ('PM', 0.0096683195),\n",
       " ('PCM', 0.007961408),\n",
       " ('BETA_m', 0.012328836),\n",
       " ('C2A', 0.00973881),\n",
       " ('OL', 0.014086157),\n",
       " ('ROE', 0.006819704),\n",
       " ('CTO', 0.0088106245),\n",
       " ('ATO', 0.008869508),\n",
       " ('LEV', 0.016589658),\n",
       " ('NOA', 0.007395937),\n",
       " ('ROA', 0.00800197),\n",
       " ('RNA', 0.007928216),\n",
       " ('OP', 0.007415824),\n",
       " ('NI', 0.009967804),\n",
       " ('INV', 0.0060835853),\n",
       " ('BETA_d', 0.010645336),\n",
       " ('R36_13', 0.0062357564),\n",
       " ('D2A', 0.009873238),\n",
       " ('FC2Y', 0.019410893),\n",
       " ('SGA2S', 0.015107715),\n",
       " ('OA', 0.00930093),\n",
       " ('AC', 0.008188342),\n",
       " ('HIGH52', 0.0066908887),\n",
       " ('R60_13', 0.010611703),\n",
       " ('DPI2A', 0.008602976)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = []\n",
    "gts = []\n",
    "train_masks = []\n",
    "for i, data in enumerate(tqdm(train_data_loader)):\n",
    "    data, mask, ordered_mask, factors = data\n",
    "    assert not torch.isnan(data).any()\n",
    "#         print(data, mask)\n",
    "    assert not torch.logical_and(data <= 0, ~mask).any(), torch.min(data * mask)\n",
    "\n",
    "    C_train = data.transpose_(0, 1).float().to(device)[:-1]\n",
    "        \n",
    "    C_mask = mask.float().to(device).transpose_(0, 1)[:-1]\n",
    "    C_ordered_mask = ordered_mask.float().to(device).transpose_(0, 1)[:-1]\n",
    "\n",
    "    factors = factors.transpose_(0, 1).float().to(device)[1:]\n",
    "\n",
    "    train_input = torch.cat([C_train, C_mask, factors], axis=2)\n",
    "\n",
    "\n",
    "    if train_input.shape[1] == 10:\n",
    "        alpha_pred, beta_pred, hidden_out = model(train_input)\n",
    "\n",
    "        model_input = torch.cat([hidden_out[:-1].detach(), C_train[1:]], axis=2)\n",
    "        batch_size, batch_length, dim = model_input.shape\n",
    "        model_input = model_input.reshape(batch_size * batch_length, dim)\n",
    "\n",
    "        C_ordered_mask_reshape = C_ordered_mask[1:].reshape(batch_size * batch_length, 45)\n",
    "        C_mask_reshape = C_ordered_mask[1:].reshape(batch_size * batch_length, 45)\n",
    "        C_train_reshape = C_train[1:].reshape(batch_size * batch_length, 45)\n",
    "\n",
    "        alphas_pred, betas_pred = ar_model(model_input)\n",
    "        pred = alphas_pred / (alphas_pred + betas_pred)\n",
    "        preds.append(pred.detach().cpu().numpy())\n",
    "        gts.append(C_train_reshape.detach().cpu().numpy())\n",
    "        train_masks.append(C_mask_reshape.detach().cpu().numpy())\n",
    "\n",
    "preds = np.concatenate(preds, axis=0)\n",
    "gts = np.concatenate(gts, axis=0)\n",
    "train_masks = np.concatenate(train_masks, axis=0)\n",
    "gts[train_masks == 1] = np.nan\n",
    "mse = np.nanmean((preds - gts)**2, axis=0)\n",
    "list(zip(chars[ordering], np.sqrt(mse)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b61cfba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acbddc3255b64702a032bf2f1b6f4ad6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/475 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "([('ME', 0.2270785),\n",
       "  ('R2_1', 0.28524897),\n",
       "  ('D2P', 0.255948),\n",
       "  ('SPREAD', 0.1669922),\n",
       "  ('RVAR', 0.13371357),\n",
       "  ('VAR', 0.14064394),\n",
       "  ('IdioVol', 0.14511827),\n",
       "  ('TURN', 0.2733414),\n",
       "  ('SUV', 0.28532574),\n",
       "  ('R12_7', 0.2755995),\n",
       "  ('CF2P', 0.23992816),\n",
       "  ('E2P', 0.24618544),\n",
       "  ('R12_2', 0.26989412),\n",
       "  ('S2P', 0.23038886),\n",
       "  ('B2M', 0.19872694),\n",
       "  ('CF2B', 0.26974013),\n",
       "  ('AT', 0.2100129),\n",
       "  ('A2ME', 0.076190904),\n",
       "  ('Q', 0.07180035),\n",
       "  ('PROF', 0.28141898),\n",
       "  ('PM', 0.23164721),\n",
       "  ('PCM', 0.2809683),\n",
       "  ('BETA_m', 0.26011577),\n",
       "  ('C2A', 0.2597642),\n",
       "  ('OL', 0.2681491),\n",
       "  ('ROE', 0.25607952),\n",
       "  ('CTO', 0.27569234),\n",
       "  ('ATO', 0.27708998),\n",
       "  ('LEV', 0.24328746),\n",
       "  ('NOA', 0.2903115),\n",
       "  ('ROA', 0.26006886),\n",
       "  ('RNA', 0.25442174),\n",
       "  ('OP', 0.25949022),\n",
       "  ('NI', 0.27820268),\n",
       "  ('INV', 0.27399093),\n",
       "  ('BETA_d', 0.27885318),\n",
       "  ('R36_13', 0.27320355),\n",
       "  ('D2A', 0.2738948),\n",
       "  ('FC2Y', 0.2561601),\n",
       "  ('SGA2S', 0.25752795),\n",
       "  ('OA', 0.28348666),\n",
       "  ('AC', 0.28339788),\n",
       "  ('HIGH52', 0.23889722),\n",
       "  ('R60_13', 0.2639537),\n",
       "  ('DPI2A', 0.28352824)],\n",
       " 0.24323288)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = []\n",
    "gts = []\n",
    "train_masks = []\n",
    "for i, data in enumerate(tqdm(train_data_loader)):\n",
    "    data, mask, ordered_mask, factors = data\n",
    "    assert not torch.isnan(data).any()\n",
    "#         assert not (data <= 0).any(), torch.min(data)\n",
    "#         print(data.shape)\n",
    "    C_train = data.transpose_(0, 1).float().to(device)[:-1]\n",
    "        \n",
    "    C_mask = mask.float().to(device).transpose_(0, 1)[:-1]\n",
    "    C_ordered_mask = ordered_mask.float().to(device).transpose_(0, 1)[:-1]\n",
    "\n",
    "    factors = factors.transpose_(0, 1).float().to(device)[1:]\n",
    "\n",
    "    train_input = torch.cat([C_train, C_mask, factors], axis=2)       \n",
    "    if train_input.shape[1] == 10:\n",
    "        alpha_pred, beta_pred,_ = model(train_input)\n",
    "\n",
    "        pred = alpha_pred / (alpha_pred + beta_pred)\n",
    "        preds.append(pred.detach().cpu().numpy())\n",
    "        gts.append(C_train.detach().cpu().numpy())\n",
    "        train_masks.append(C_mask.detach().cpu().numpy())\n",
    "\n",
    "preds = np.concatenate(preds, axis=0)\n",
    "gts = np.concatenate(gts, axis=0)\n",
    "train_masks = np.concatenate(train_masks, axis=0)\n",
    "gts[train_masks == 1] = np.nan\n",
    "\n",
    "mse = np.nanmean((preds - gts)**2, axis=(0,1))\n",
    "list(zip(chars[ordering], np.sqrt(mse))), np.mean(np.sqrt(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138589c4",
   "metadata": {},
   "source": [
    "# OOS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19746832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function print>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2dd10ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import data_loading\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46c75f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['A2ME', 'AC', 'AT', 'ATO', 'B2M', 'BETA_d', 'BETA_m', 'C2A', 'CF2B',\n",
      "       'CF2P', 'CTO', 'D2A', 'D2P', 'DPI2A', 'E2P', 'FC2Y', 'HIGH52', 'INV',\n",
      "       'IdioVol', 'LEV', 'ME', 'NI', 'NOA', 'OA', 'OL', 'OP', 'PCM', 'PM',\n",
      "       'PROF', 'Q', 'R12_2', 'R12_7', 'R2_1', 'R36_13', 'R60_13', 'RNA', 'ROA',\n",
      "       'ROE', 'RVAR', 'S2P', 'SGA2S', 'SPREAD', 'SUV', 'TURN', 'VAR', 'return',\n",
      "       'date', 'permno', 'monthly_update'],\n",
      "      dtype='object')\n",
      "['A2ME' 'AC' 'AT' 'ATO' 'B2M' 'BETA_d' 'BETA_m' 'C2A' 'CF2B' 'CF2P' 'CTO'\n",
      " 'D2A' 'D2P' 'DPI2A' 'E2P' 'FC2Y' 'HIGH52' 'INV' 'IdioVol' 'LEV' 'ME' 'NI'\n",
      " 'NOA' 'OA' 'OL' 'OP' 'PCM' 'PM' 'PROF' 'Q' 'R12_2' 'R12_7' 'R2_1'\n",
      " 'R36_13' 'R60_13' 'RNA' 'ROA' 'ROE' 'RVAR' 'S2P' 'SGA2S' 'SPREAD' 'SUV'\n",
      " 'TURN' 'VAR']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 648/648 [02:58<00:00,  3.63it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "percentile_rank_chars, _, chars, _,\\\n",
    "    _, _, _, monthly_updates = data_loading.get_data_panel(\"../Data/raw_chars_returns_df_all_dates_yearly_fb.fthr\",\n",
    "                                                            \"../Data/ff_rf.csv\", computstat_data_present_filter=True,\n",
    "                                                                              financial_firm_filter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d80097c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "any_present = np.any(~np.isnan(percentile_rank_chars), axis=2)\n",
    "present_counts = np.sum(np.sum(np.logical_and(~np.isnan(percentile_rank_chars),\n",
    "                                             np.expand_dims(any_present, axis=2)), axis=0), axis=0)\n",
    "del any_present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00a34a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ME' 'R2_1' 'D2P' 'SPREAD' 'RVAR' 'VAR' 'IdioVol' 'TURN' 'SUV' 'R12_7'\n",
      " 'CF2P' 'E2P' 'R12_2' 'S2P' 'B2M' 'CF2B' 'AT' 'A2ME' 'Q' 'PROF' 'PM' 'PCM'\n",
      " 'BETA_m' 'C2A' 'OL' 'ROE' 'CTO' 'ATO' 'LEV' 'NOA' 'ROA' 'RNA' 'OP' 'NI'\n",
      " 'INV' 'BETA_d' 'R36_13' 'D2A' 'FC2Y' 'SGA2S' 'OA' 'AC' 'HIGH52' 'R60_13'\n",
      " 'DPI2A']\n"
     ]
    }
   ],
   "source": [
    "ordering = np.argsort(present_counts)[::-1]\n",
    "print(chars[ordering])\n",
    "percentile_rank_chars = percentile_rank_chars[:,:,ordering]\n",
    "chars = chars[ordering]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "259c3f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_groupings  = [('A2ME', \"Q\"),\n",
    "                   ('AC', 'Q'),\n",
    "('AT', 'Q'),\n",
    "('ATO', 'Q'),\n",
    "('B2M', 'QM'),\n",
    "('BETA_d', 'M'),\n",
    "('BETA_m', 'M'),\n",
    "('C2A', 'Q'),\n",
    "('CF2B', 'Q'),\n",
    "('CF2P', 'QM'),\n",
    "('CTO', 'Q'),\n",
    "('D2A', 'Q'),\n",
    "('D2P', 'M'),\n",
    "('DPI2A', 'Q'),\n",
    "('E2P', 'QM'),\n",
    "('FC2Y', 'QY'),\n",
    "('IdioVol', 'M'),\n",
    "('INV', 'Q'),\n",
    "('LEV', 'Q'),\n",
    "('ME', 'M'),\n",
    "('TURN', 'M'),\n",
    "('NI', 'Q'),\n",
    "('NOA', 'Q'),\n",
    "('OA', 'Q'),\n",
    "('OL', 'Q'),\n",
    "('OP', 'Q'),\n",
    "('PCM', 'Q'),\n",
    "('PM', 'Q'),\n",
    "('PROF', 'QY'),\n",
    "('Q', 'QM'),\n",
    "('R2_1', 'M'),\n",
    "('R12_2', 'M'),\n",
    "('R12_7', 'M'),\n",
    "('R36_13', 'M'),\n",
    "('R60_13', 'M'),\n",
    "('HIGH52', 'M'),\n",
    "('RVAR', 'M'),\n",
    "('RNA', 'Q'),\n",
    "('ROA', 'Q'),\n",
    "('ROE', 'Q'),\n",
    "('S2P', 'QM'),\n",
    "('SGA2S', 'Q'),\n",
    "('SPREAD', 'M'),\n",
    "('SUV', 'M'),\n",
    "('VAR', 'M')]\n",
    "char_map = {x[0]:x[1] for x in char_groupings}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74e95ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_imputation(name, full=False):\n",
    "    base_path = '../Data/'\n",
    "    result_file_name = base_path + name + '.npz'\n",
    "    res = np.load(result_file_name)\n",
    "    if not full:\n",
    "        return res['data']\n",
    "    else:\n",
    "        return res['data'], res['dates'], res['permnos'], res['chars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9de3826",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2029b114",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_replace = np.isnan(masked_data[:400])\n",
    "masked_data[:400][to_replace] = percentile_rank_chars[:400][to_replace]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5aa76fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded\n",
      "loaded\n",
      "loaded\n"
     ]
    }
   ],
   "source": [
    "masked_data = load_imputation('MAR_fit_data')[:, :, ordering]\n",
    "print(\"loaded\")\n",
    "eval_data = load_imputation('MAR_eval_data')[400:, :, ordering]\n",
    "print(\"loaded\")\n",
    "gamma_ts = load_imputation('MAR_xs_factors')\n",
    "print(\"loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33da1197",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gamma_ts = np.load('../Data/gamma_ts_save.npz')['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22e711c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 400/400 [00:07<00:00, 55.52it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data_seq = data_loading.get_data(percentile_rank_chars[:400], min_chars_present=20, fill_val=-1, \n",
    "                                   gamma_ts=train_gamma_ts[:400], ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ed4037c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8770"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32cf6156",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 51.05it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 148/148 [00:02<00:00, 60.93it/s]\n"
     ]
    }
   ],
   "source": [
    "eval_data_seq = data_loading.get_data(masked_data[400:500], min_chars_present=20, fill_val=-1, \n",
    "                                   gamma_ts=gamma_ts[400:500], ordered=False,\n",
    "                    oos_mask=~np.isnan(eval_data[:100]), oos_eval_data=eval_data[:100])\n",
    "test_data_seq = data_loading.get_data(masked_data[500:], min_chars_present=20, fill_val=-1, \n",
    "                                   gamma_ts=gamma_ts[500:], ordered=False,\n",
    "                    oos_mask=~np.isnan(eval_data[100:]), oos_eval_data=eval_data[100:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a7b39e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3159, 3220)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(eval_data_seq), len(test_data_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c63c92b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'data_loading' from '/home/selwin_p_george/CS 236 Project/Code/data_loading.py'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(data_loading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ca5f210",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dataset = data_loading.ListDatasetWithFactors(train_data_seq, batch_size=50)\n",
    "train_data_loader = data_loading.DataLoader(all_dataset, batch_size=10, shuffle=True, num_workers=4)\n",
    "\n",
    "all_dataset = data_loading.ListDatasetWithFactors(eval_data_seq, batch_size=50,\n",
    "                                                 return_oos_data=True)\n",
    "eval_data_loader = data_loading.DataLoader(all_dataset, batch_size=10, shuffle=True, num_workers=4)\n",
    "\n",
    "all_dataset = data_loading.ListDatasetWithFactors(test_data_seq, batch_size=50,\n",
    "                                                 return_oos_data=True)\n",
    "test_data_loader = data_loading.DataLoader(all_dataset, batch_size=10, shuffle=True, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b934760c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import models\n",
    "import loss_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb629dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "381c9fd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'models' from '/home/selwin_p_george/CS 236 Project/Code/models.py'>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4458dece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 1., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 0.]], requires_grad=True) torch.Size([45, 51])\n",
      "torch device is cuda:0\n",
      "epoch 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5f3419a142f4d8e9f941f0c9795a682",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1201 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 avg lstm loss 21.975215911865234, avg ar model loss 185.47482299804688\n",
      "epoch 0 took 0.6181668559710185 minutes\n",
      "epoch 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f29eae8c65664b289f2f7dd8de7904f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1201 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2790/810536002.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mnet_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0mnet_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m             \u001b[0mar_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = models.XSCharLSTM(input_dim=96, hiddin_dim=15, num_layers=2, batch_size=10)\n",
    "ar_model = models.Beta_NADE(hidden_state_dim=6)\n",
    "\n",
    "num_epochs = 41\n",
    "eval_freq = 10\n",
    "\n",
    "optimizer = torch.optim.Adam(list(model.parameters()) + list(ar_model.parameters()), lr=0.01)\n",
    "\n",
    "\n",
    "scheduler = MultiStepLR(optimizer, [20, 35], gamma=0.1, last_epoch=-1)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'torch device is {device}')\n",
    "model = model.to(device)\n",
    "ar_model = ar_model.to(device)\n",
    "loss_fn = loss_functions.beta_ll_loss\n",
    "\n",
    "\n",
    "#basic training loop for local development\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_start = time.time()\n",
    "    losses = []\n",
    "    ar_losses = []\n",
    "    # Forward pass\n",
    "    print(f'epoch {epoch}')\n",
    "    for i, data in enumerate(tqdm(train_data_loader)):\n",
    "        data, mask, ordered_mask, factors = data\n",
    "        assert not torch.isnan(data).any()\n",
    "#         print(data, mask)\n",
    "        assert not torch.logical_and(data <= 0, ~mask).any(), torch.min(data * mask)\n",
    "        \n",
    "        C_train = data.transpose_(0, 1).float().to(device)[:-1]\n",
    "        \n",
    "        C_mask = mask.float().to(device).transpose_(0, 1)[:-1]\n",
    "        C_ordered_mask = ordered_mask.float().to(device).transpose_(0, 1)[:-1]\n",
    "        \n",
    "        factors = factors.transpose_(0, 1).float().to(device)[1:]\n",
    "        \n",
    "        train_input = torch.cat([C_train, C_mask, factors], axis=2)\n",
    "        \n",
    "      \n",
    "        if train_input.shape[1] == 10:\n",
    "            alpha_pred, beta_pred, hidden_out = model(train_input)\n",
    "            loss = loss_fn(C_train[1:], alpha_pred[:-1], beta_pred[:-1], mask=C_mask[1:]).mean()\n",
    "            assert not torch.isnan(loss).any()\n",
    "            \n",
    "#             loss.backward()\n",
    "            losses.append(loss.data.detach().cpu().numpy())\n",
    "            \n",
    "#             print(hidden_out.shape, C_train.shape)\n",
    "            model_input = torch.cat([hidden_out[:-1].detach(), C_train[1:]], axis=2)\n",
    "            batch_size, batch_length, dim = model_input.shape\n",
    "            model_input = model_input.reshape(batch_size * batch_length, dim)\n",
    "            \n",
    "            C_ordered_mask_reshape = C_ordered_mask[1:].reshape(batch_size * batch_length, 45)\n",
    "            C_train_reshape = C_train[1:].reshape(batch_size * batch_length, 45)\n",
    "\n",
    "            alphas_pred, betas_pred = ar_model(model_input)\n",
    "            \n",
    "            ar_loss = loss_fn(C_train_reshape,\n",
    "                              alphas_pred, betas_pred, mask=C_ordered_mask_reshape,\n",
    "                             reduce_axis=1).mean()\n",
    "            \n",
    "            net_loss = ar_loss + loss\n",
    "            net_loss.backward()\n",
    "            ar_losses.append(ar_loss.data.detach().cpu().numpy())\n",
    "            \n",
    "#             if i % 100 == 0:\n",
    "#                 print(loss)\n",
    "#                 print(ar_loss)\n",
    "            \n",
    "#             if i % 10 == 0:\n",
    "    #             torch.nn.utils.clip_grad_norm_(model.parameters(), 50)\n",
    "            optimizer.step()\n",
    "            model.zero_grad()\n",
    "            optimizer.zero_grad()       \n",
    "\n",
    "    print(f'epoch {epoch} avg lstm loss {np.mean(losses)}, avg ar model loss {np.mean(ar_losses)}')\n",
    "    print(f'epoch {epoch} took {(time.time() - epoch_start)/60.0} minutes')\n",
    "    scheduler.step()\n",
    "    if (epoch + 1) % 5 == 0 :\n",
    "        if epoch > 5:\n",
    "            print(eval_model_is(model, ar_model, train_data_loader))\n",
    "        print(eval_model_oos(model, ar_model, eval_data_loader))\n",
    "        print(eval_ts_model_oos(model, eval_data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199adce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch device is cuda:0\n",
      "epoch 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7e85a09871f47d391a16f1c0c8f7757",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/867 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 avg loss -27.41938591003418\n",
      "epoch 0 took 0.2311870018641154 minutes\n",
      "epoch 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5a2d7bcd2eb4b86a68fef80eee2f409",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/867 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 avg loss -28.285863876342773\n",
      "epoch 1 took 0.22755613327026367 minutes\n",
      "epoch 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17f08c1870cb45229cb64d463cd6330e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/867 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 avg loss -28.896570205688477\n",
      "epoch 2 took 0.22944363753000896 minutes\n",
      "epoch 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8efc3a3023549659829a39d82fe8825",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/867 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 avg loss -29.43558692932129\n",
      "epoch 3 took 0.23070388634999592 minutes\n",
      "epoch 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ec8dbcc3c49452a97c63bc9b4b69114",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/867 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 avg loss -29.62164878845215\n",
      "epoch 4 took 0.22995700438817343 minutes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7367385de0e64c32a48c9f54b9bc00cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/867 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([('PM', 0.05645385), ('OP', 0.28496397), ('R12_2', 0.23886305), ('AC', 0.19193292), ('FC2Y', 0.12536913), ('DPI2A', 0.12668872), ('Q', 0.17025982), ('R60_13', 0.24542794), ('HIGH52', 0.31151417), ('RNA', 0.26196468), ('R12_7', 0.18307874), ('B2M', 0.1895414), ('ROA', 0.25264734), ('SGA2S', 0.06167091), ('RVAR', 0.08041114), ('SUV', 0.2606837), ('D2P', 0.05225271), ('ME', 0.04988145), ('NOA', 0.05747349), ('LEV', 0.15365794), ('ATO', 0.13477227), ('CTO', 0.1481755), ('IdioVol', 0.24130991), ('TURN', 0.19668646), ('OL', 0.07391778), ('D2A', 0.1865677), ('CF2P', 0.068723105), ('SPREAD', 0.13150816), ('PROF', 0.12289102), ('BETA_m', 0.1409528), ('R36_13', 0.1612591), ('BETA_d', 0.1635983), ('ROE', 0.1795687), ('PCM', 0.26955143), ('A2ME', 0.24927293), ('VAR', 0.19513877), ('NI', 0.258634), ('E2P', 0.27188647), ('CF2B', 0.10696274), ('OA', 0.09801844), ('C2A', 0.28298408), ('R2_1', 0.27868184), ('AT', 0.24047388), ('INV', 0.24977198), ('S2P', 0.27595797)], 0.17960006)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa6cf51bdc344854bcf897a9f6881ef4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/145 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([('PM', 0.3600535), ('OP', 0.302347), ('R12_2', 0.38641512), ('AC', 0.47120982), ('FC2Y', 0.52939385), ('DPI2A', 0.5337513), ('Q', 0.49544728), ('R60_13', 0.43271548), ('HIGH52', 0.32429808), ('RNA', 0.32548574), ('R12_7', 0.36403808), ('B2M', 0.40380985), ('ROA', 0.3356782), ('SGA2S', 0.37681192), ('RVAR', 0.3377897), ('SUV', 0.34266493), ('D2P', 0.32806727), ('ME', 0.36976886), ('NOA', 0.3599634), ('LEV', 0.3724845), ('ATO', 0.4213244), ('CTO', 0.34770015), ('IdioVol', 0.41446176), ('TURN', 0.311686), ('OL', 0.45485267), ('D2A', 0.37681013), ('CF2P', 0.43296513), ('SPREAD', 0.46380925), ('PROF', 0.3650012), ('BETA_m', 0.33866328), ('R36_13', 0.3968188), ('BETA_d', 0.3891552), ('ROE', 0.38328192), ('PCM', 0.32268712), ('A2ME', 0.32326034), ('VAR', 0.4948043), ('NI', 0.329451), ('E2P', 0.35026938), ('CF2B', 0.43634418), ('OA', 0.42467943), ('C2A', 0.294962), ('R2_1', 0.29952744), ('AT', 0.3887503), ('INV', 0.32284355), ('S2P', 0.31827474)], 0.38121286)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0aefbe87a3d4b54b2ccc2377a6d151d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/145 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([('ME', 0.43425798), ('R2_1', 0.3054431), ('D2P', 0.38403547), ('SPREAD', 0.4503317), ('RVAR', 0.50759584), ('VAR', 0.5335387), ('IdioVol', 0.5387925), ('TURN', 0.41437155), ('SUV', 0.32721218), ('R12_7', 0.32466507), ('CF2P', 0.35687298), ('E2P', 0.399974), ('R12_2', 0.3390162), ('S2P', 0.3874171), ('B2M', 0.3745102), ('CF2B', 0.34708893), ('AT', 0.43662795), ('A2ME', 0.41355953), ('Q', 0.47627062), ('PROF', 0.3873684), ('PM', 0.4320488), ('PCM', 0.3578543), ('BETA_m', 0.40684876), ('C2A', 0.31968242), ('OL', 0.46613026), ('ROE', 0.37472534), ('CTO', 0.46698678), ('ATO', 0.4595624), ('LEV', 0.37836447), ('NOA', 0.40051714), ('ROA', 0.39586267), ('RNA', 0.401288), ('OP', 0.38684797), ('NI', 0.31468132), ('INV', 0.31477284), ('BETA_d', 0.49443033), ('R36_13', 0.32518187), ('D2A', 0.3511921), ('FC2Y', 0.445422), ('SGA2S', 0.43802702), ('OA', 0.2980987), ('AC', 0.30050844), ('HIGH52', 0.38488606), ('R60_13', 0.31619057), ('DPI2A', 0.32267034)], 0.39314955)\n",
      "epoch 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "421611ffdcfb40b2b9339109f0d3d301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/867 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 avg loss -30.002809524536133\n",
      "epoch 5 took 0.232193128267924 minutes\n",
      "epoch 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ae7435301d5494d9f2641d11587978b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/867 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 avg loss -30.217166900634766\n",
      "epoch 6 took 0.23060224453608194 minutes\n",
      "epoch 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a0f4c130d3d472b8846f2ea47ab082d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/867 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7 avg loss -30.455570220947266\n",
      "epoch 7 took 0.22894989252090453 minutes\n",
      "epoch 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3a6cba6a2fb44f1931d4a95abf80af5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/867 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model = models.XSCharLSTM(input_dim=96, hidden_dim=15, num_layers=2, batch_size=10)\n",
    "\n",
    "num_epochs = 41\n",
    "eval_freq = 10\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "\n",
    "scheduler = MultiStepLR(optimizer, [20, 30], gamma=0.1, last_epoch=-1)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'torch device is {device}')\n",
    "model = model.to(device)\n",
    "loss_fn = loss_functions.beta_ll_loss\n",
    "\n",
    "\n",
    "#basic training loop for local development\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_start = time.time()\n",
    "    losses = []\n",
    "    # Forward pass\n",
    "    print(f'epoch {epoch}')\n",
    "    for i, data in enumerate(tqdm(train_data_loader)):\n",
    "        data, mask, ordered_mask, factors = data\n",
    "        assert not torch.isnan(data).any()\n",
    "#         assert not (data <= 0).any(), torch.min(data)\n",
    "#         print(data.shape)\n",
    "        C_train = data.transpose_(0, 1).float().to(device)[:-1]\n",
    "        \n",
    "        C_mask = mask.float().to(device).transpose_(0, 1)[:-1]\n",
    "        C_ordered_mask = ordered_mask.float().to(device).transpose_(0, 1)[:-1]\n",
    "        \n",
    "        factors = factors.transpose_(0, 1).float().to(device)[1:]\n",
    "        \n",
    "        train_input = torch.cat([C_train, C_mask, factors], axis=2)\n",
    "        \n",
    "        if train_input.shape[1] == 10 and train_input.shape[2] > 0:\n",
    "#             print(train_input.shape)\n",
    "            alpha_pred, beta_pred, hidden_out = model(train_input)\n",
    "#             print(hidden_out.shape)\n",
    "\n",
    "            loss = loss_fn(C_train[1:], alpha_pred[:-1], beta_pred[:-1], mask=C_mask[1:]).mean()\n",
    "            assert not torch.isnan(loss).any()\n",
    "\n",
    "            loss.backward()\n",
    "            losses.append(loss.data.cpu().detach().numpy())\n",
    "\n",
    "            optimizer.step()\n",
    "            model.zero_grad()\n",
    "            optimizer.zero_grad()       \n",
    "\n",
    "\n",
    "    print(f'epoch {epoch} avg loss {np.mean(losses)}')\n",
    "    print(f'epoch {epoch} took {(time.time() - epoch_start)/60.0} minutes')\n",
    "    scheduler.step()\n",
    "    \n",
    "    if (epoch + 1) % 5 == 0 :\n",
    "        print(eval_ts_model_is(model, train_data_loader))\n",
    "        print(eval_ts_model_is(model, eval_data_loader))\n",
    "        print(eval_ts_model_oos(model, eval_data_loader))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4c78c164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 1., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 0.]], requires_grad=True) torch.Size([45, 51])\n",
      "torch device is cuda:0\n",
      "epoch 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03e0bae7bba442699f733564be294183",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1087 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 avg lstm loss 30.574478149414062, avg ar model loss 220.91648864746094\n",
      "epoch 0 took 0.5572269320487976 minutes\n",
      "epoch 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8fe07d7a037421ca6811a5a004a52f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1087 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 avg lstm loss 0.25716617703437805, avg ar model loss 3.7249555587768555\n",
      "epoch 1 took 0.556424061457316 minutes\n",
      "epoch 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c3f25f9399744c49dead178d2f9c1d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1087 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 avg lstm loss 0.30200842022895813, avg ar model loss -0.3374493420124054\n",
      "epoch 2 took 0.5536059816678365 minutes\n",
      "epoch 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "613a7c7f1cd942169d8d787483915c05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1087 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 avg lstm loss 0.33025604486465454, avg ar model loss -2.3161463737487793\n",
      "epoch 3 took 0.5563517888387044 minutes\n",
      "epoch 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3df91b6474242c5ab26b09e91740756",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1087 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 avg lstm loss 0.33342882990837097, avg ar model loss -44.94136428833008\n",
      "epoch 4 took 0.5525907516479492 minutes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b3173ad6a194974b220987aed76ca4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/147 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ME', 0.24577402), ('R2_1', 0.47361138), ('D2P', 0.4939099), ('SPREAD', 0.49990743), ('RVAR', 0.2954363), ('VAR', 0.3030001), ('IdioVol', 0.44847497), ('TURN', 0.4596296), ('SUV', 0.43495527), ('R12_7', 0.37241763), ('CF2P', 0.48267815), ('E2P', 0.52373034), ('R12_2', 0.47211272), ('S2P', 0.24437961), ('B2M', 0.46391347), ('CF2B', 0.4691021), ('AT', 0.2623877), ('A2ME', 0.15946482), ('Q', 0.17722492), ('PROF', 0.4482211), ('PM', 0.40840417), ('PCM', 0.42743492), ('BETA_m', 0.43040103), ('C2A', 0.44304165), ('OL', 0.23972884), ('ROE', 0.4591513), ('CTO', 0.22031291), ('ATO', 0.54526633), ('LEV', 0.423649), ('NOA', 0.3534095), ('ROA', 0.33273214), ('RNA', 0.4540379), ('OP', 0.48291898), ('NI', 0.27456903), ('INV', 0.39497867), ('BETA_d', 0.32214803), ('R36_13', 0.44015402), ('D2A', 0.44328415), ('FC2Y', 0.29288214), ('SGA2S', 0.2570058), ('OA', 0.49264896), ('AC', 0.29029575), ('HIGH52', 0.46844345), ('R60_13', 0.44889066), ('DPI2A', 0.28315923)]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "decbee8bd6024340a40d0c27a4789dec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/147 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ME', 0.029101584), ('R2_1', 0.048254486), ('D2P', 0.021670131), ('SPREAD', 0.024338383), ('RVAR', 0.025241045), ('VAR', 0.03500163), ('IdioVol', 0.024337992), ('TURN', 0.022205163), ('SUV', 0.026813956), ('R12_7', 0.022936514), ('CF2P', 0.016156947), ('E2P', 0.018877938), ('R12_2', 0.02871753), ('S2P', 0.03640639), ('B2M', 0.04321435), ('CF2B', 0.047337316), ('AT', 0.02659732), ('A2ME', 0.025906298), ('Q', 0.029438904), ('PROF', 0.023668787), ('PM', 0.07374988), ('PCM', 0.031668495), ('BETA_m', 0.03244632), ('C2A', 0.052716315), ('OL', 0.020441514), ('ROE', 0.038060576), ('CTO', 0.033175524), ('ATO', 0.013707122), ('LEV', 0.033594843), ('NOA', 0.017321926), ('ROA', 0.01612252), ('RNA', nan), ('OP', nan), ('NI', nan), ('INV', nan), ('BETA_d', nan), ('R36_13', nan), ('D2A', nan), ('FC2Y', nan), ('SGA2S', nan), ('OA', nan), ('AC', nan), ('HIGH52', nan), ('R60_13', nan), ('DPI2A', nan)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2790/4016302882.py:44: RuntimeWarning: Mean of empty slice\n",
      "  mse = np.nanmean((preds - gts)**2, axis=0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9708736f67304740bf45d56a23b3cf53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/147 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([('ME', 0.2780454), ('R2_1', 0.29105762), ('D2P', 0.28419092), ('SPREAD', 0.28753972), ('RVAR', 0.27715212), ('VAR', 0.27934894), ('IdioVol', 0.2791319), ('TURN', 0.2969754), ('SUV', 0.2841043), ('R12_7', 0.29208812), ('CF2P', 0.3003789), ('E2P', 0.29083437), ('R12_2', 0.29024473), ('S2P', 0.29821026), ('B2M', 0.28724137), ('CF2B', 0.2836242), ('AT', 0.27082506), ('A2ME', 0.286033), ('Q', 0.28707698), ('PROF', 0.28969264), ('PM', 0.28559506), ('PCM', 0.2913965), ('BETA_m', 0.29363754), ('C2A', 0.28604436), ('OL', 0.2918379), ('ROE', 0.28423777), ('CTO', 0.2917722), ('ATO', 0.299982), ('LEV', 0.29161385), ('NOA', 0.29174387), ('ROA', 0.28542632), ('RNA', 0.2870515), ('OP', 0.28835502), ('NI', 0.29501498), ('INV', 0.289779), ('BETA_d', 0.30911466), ('R36_13', 0.28908262), ('D2A', 0.2968097), ('FC2Y', 0.29176155), ('SGA2S', 0.2949487), ('OA', 0.29162326), ('AC', 0.29459777), ('HIGH52', 0.28564763), ('R60_13', 0.29424345), ('DPI2A', 0.29457107)], 0.28954852)\n",
      "epoch 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1afaccf428d04c1484471e05ff0e1aca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1087 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 avg lstm loss 0.32911252975463867, avg ar model loss -68.31160736083984\n",
      "epoch 5 took 0.5584673086802164 minutes\n",
      "epoch 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31b0c51155a04e698b40174a64c4b678",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1087 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 avg lstm loss 0.2898271679878235, avg ar model loss -72.7917251586914\n",
      "epoch 6 took 0.5568855126698812 minutes\n",
      "epoch 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceee640b9b1949ffab10ca9346a333ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1087 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7 avg lstm loss 0.28612658381462097, avg ar model loss -74.33876037597656\n",
      "epoch 7 took 0.5531476895014446 minutes\n",
      "epoch 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d3dfeb8b35b4bbb8badeae138500cad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1087 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8 avg lstm loss 0.30036720633506775, avg ar model loss -75.2610092163086\n",
      "epoch 8 took 0.5536255081494649 minutes\n",
      "epoch 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7018349a5e1c491e9a62849bffbe3a6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1087 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9 avg lstm loss 0.2895807921886444, avg ar model loss -75.99514770507812\n",
      "epoch 9 took 0.5566335956255595 minutes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "400b83d1ae58455aa0be475ff56685c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1087 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2790/1868360392.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_model_is\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mar_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_model_oos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mar_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_data_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_model_is\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mar_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_data_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2790/4016302882.py\u001b[0m in \u001b[0;36meval_model_is\u001b[0;34m(model, ar_model, data_loader)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mC_train_reshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mC_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m45\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mgts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC_train_reshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/CS 236 Project/Code/models.py\u001b[0m in \u001b[0;36mimpute\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;31m#         print(num_missing)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0malphas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbetas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape_vectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_copy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malphas\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0malphas\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbetas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;31m#             print(x_copy)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/CS 236 Project/Code/models.py\u001b[0m in \u001b[0;36mshape_vectors\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0mx_diag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_j\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx_j\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;31m# Compute xi*Wi + bi for each dimension in each sample.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mbeta_dot_products\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_beta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_diag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m         \u001b[0;31m# Sigmoids of prefix sums of above to get hidden activations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0mhidden_beta_activations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta_dot_products\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = models.XSCharLSTM(input_dim=96, hidden_dim=6, num_layers=2, batch_size=10)\n",
    "ar_model = models.Beta_NADE(hidden_state_dim=6)\n",
    "\n",
    "num_epochs = 41\n",
    "eval_freq = 10\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "ar_optimizer = torch.optim.Adam(ar_model.parameters(), lr=0.01)\n",
    "\n",
    "\n",
    "scheduler = MultiStepLR(optimizer, [10, 20], gamma=0.1, last_epoch=-1)\n",
    "ar_scheduler = MultiStepLR(ar_optimizer, [10, 20], gamma=0.1, last_epoch=-1)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'torch device is {device}')\n",
    "model = model.to(device)\n",
    "ar_model = ar_model.to(device)\n",
    "loss_fn = loss_functions.beta_ll_loss\n",
    "\n",
    "\n",
    "#basic training loop for local development\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_start = time.time()\n",
    "    losses = []\n",
    "    ar_losses = []\n",
    "    # Forward pass\n",
    "    print(f'epoch {epoch}')\n",
    "    for i, data in enumerate(tqdm(train_data_loader)):\n",
    "        data, mask, ordered_mask, factors = data\n",
    "        assert not torch.isnan(data).any()\n",
    "#         print(data, mask)\n",
    "        assert not torch.logical_and(data <= 0, ~mask).any(), torch.min(data * mask)\n",
    "        \n",
    "        C_train = data.transpose_(0, 1).float().to(device)[:-1]\n",
    "        \n",
    "        C_mask = mask.float().to(device).transpose_(0, 1)[:-1]\n",
    "        C_ordered_mask = ordered_mask.float().to(device).transpose_(0, 1)[:-1]\n",
    "        \n",
    "        factors = factors.transpose_(0, 1).float().to(device)[1:]\n",
    "        \n",
    "        train_input = torch.cat([C_train, C_mask, factors], axis=2)\n",
    "        \n",
    "      \n",
    "        if train_input.shape[1] == 10:\n",
    "            alpha_pred, beta_pred, hidden_out = model(train_input)\n",
    "            loss = loss_fn(C_train[1:], alpha_pred[:-1], beta_pred[:-1], mask=C_mask[1:]).mean()\n",
    "            assert not torch.isnan(loss).any()\n",
    "            \n",
    "            loss.backward()\n",
    "            losses.append(loss.data.detach().cpu().numpy())\n",
    "            \n",
    "            model_input = torch.cat([hidden_out[:-1].detach(), C_train[1:]], axis=2)\n",
    "            batch_size, batch_length, dim = model_input.shape\n",
    "            model_input = model_input.reshape(batch_size * batch_length, dim)\n",
    "            \n",
    "            \n",
    "            \n",
    "            C_ordered_mask_reshape = C_ordered_mask[1:].reshape(batch_size * batch_length, 45)\n",
    "            C_train_reshape = C_train[1:].reshape(batch_size * batch_length, 45)\n",
    "\n",
    "            alphas_pred, betas_pred = ar_model(model_input)\n",
    "            \n",
    "            \n",
    "            ar_loss = loss_fn(C_train_reshape,\n",
    "                              alphas_pred, betas_pred, mask=C_ordered_mask_reshape,\n",
    "                             reduce_axis=1).mean()\n",
    "            ar_loss.backward()\n",
    "                        \n",
    "#             for i in range(50):\n",
    "#                 model_input = model_input[0:1]\n",
    "#                 model_input.requires_grad_(True)\n",
    "#                 alphas_pred, betas_pred = ar_model(model_input)\n",
    "#                 res = torch.sum(input_mask * alphas_pred)\n",
    "#                 print(res, res.shape, res.requires_grad)\n",
    "#                 print(model_input.shape, model_input.requires_grad)\n",
    "#                 input_mask = torch.zeros_like(alphas_pred).to(device)\n",
    "#                 input_mask[0,i] = 1\n",
    "#                 print(i, torch.autograd.grad(res, model_input, create_graph=True))\n",
    "            \n",
    "            ar_losses.append(ar_loss.data.detach().cpu().numpy())\n",
    "            \n",
    "            optimizer.step()\n",
    "            model.zero_grad()\n",
    "            optimizer.zero_grad()       \n",
    "\n",
    "            ar_optimizer.step()\n",
    "            ar_model.zero_grad()\n",
    "            ar_optimizer.zero_grad()\n",
    "\n",
    "    print(f'epoch {epoch} avg lstm loss {np.mean(losses)}, avg ar model loss {np.mean(ar_losses)}')\n",
    "    print(f'epoch {epoch} took {(time.time() - epoch_start)/60.0} minutes')\n",
    "    scheduler.step()\n",
    "    ar_scheduler.step()\n",
    "    if (epoch + 1) % 5 == 0 :\n",
    "        if epoch > 5:\n",
    "            print(eval_model_is(model, ar_model, train_data_loader))\n",
    "        print(eval_model_oos(model, ar_model, eval_data_loader))\n",
    "        print(eval_model_is(model, ar_model, eval_data_loader))\n",
    "        print(eval_ts_model_oos(model, eval_data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c84fdb22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "463bdb00d4d94df196309b03714ca10a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/229 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ME', 0.020979393), ('R2_1', 0.018724356), ('D2P', 0.020316055), ('SPREAD', 0.008505484), ('RVAR', 0.030901603), ('VAR', 0.019735536), ('IdioVol', 0.017966697), ('TURN', 0.017070426), ('SUV', 0.013819655), ('R12_7', 0.0087153455), ('CF2P', 0.015446254), ('E2P', 0.013744907), ('R12_2', 0.008174245), ('S2P', 0.036648627), ('B2M', 0.01940259), ('CF2B', 0.013394699), ('AT', 0.01928784), ('A2ME', 0.023121843), ('Q', 0.026546005), ('PROF', 0.011085588), ('PM', 0.02612281), ('PCM', 0.007775547), ('BETA_m', 0.01722477), ('C2A', 0.21348476), ('OL', 0.03987289), ('ROE', 0.017378375), ('CTO', 0.020674225), ('ATO', 0.022585293), ('LEV', 0.006827993), ('NOA', nan), ('ROA', nan), ('RNA', nan), ('OP', nan), ('NI', nan), ('INV', nan), ('BETA_d', nan), ('R36_13', nan), ('D2A', nan), ('FC2Y', nan), ('SGA2S', nan), ('OA', nan), ('AC', nan), ('HIGH52', nan), ('R60_13', nan), ('DPI2A', nan)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2790/4016302882.py:44: RuntimeWarning: Mean of empty slice\n",
      "  mse = np.nanmean((preds - gts)**2, axis=0)\n"
     ]
    }
   ],
   "source": [
    "print(eval_model_is(model, ar_model, test_data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a5aa858f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c27a083306364b48a7edcd570316eea0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/147 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bb86463fa904b32a68fd6a77e700a48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1087 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2790/3991519452.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_model_oos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mar_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_data_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_model_is\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mar_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_2790/3377864958.py\u001b[0m in \u001b[0;36meval_model_is\u001b[0;34m(model, ar_model, data_loader)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mC_train_reshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mC_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m45\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mgts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC_train_reshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/CS 236 Project/Code/models.py\u001b[0m in \u001b[0;36mimpute\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;31m#         print(num_missing)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0malphas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbetas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape_vectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_copy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malphas\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0malphas\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbetas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;31m#             print(x_copy)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/CS 236 Project/Code/models.py\u001b[0m in \u001b[0;36mshape_vectors\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshape_vectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;31m# Expand each sample as a diagonal matrix.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0mx_diag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_j\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx_j\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0;31m# Compute xi*Wi + bi for each dimension in each sample.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mbeta_dot_products\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_beta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_diag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/CS 236 Project/Code/models.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshape_vectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;31m# Expand each sample as a diagonal matrix.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0mx_diag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_j\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx_j\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0;31m# Compute xi*Wi + bi for each dimension in each sample.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mbeta_dot_products\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_beta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_diag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(eval_model_oos(model, ar_model, eval_data_loader), eval_model_is(model, ar_model, train_data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e8eb30e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model_is(model, ar_model, data_loader):\n",
    "    preds = []\n",
    "    gts = []\n",
    "    train_masks = []\n",
    "    for i, data in enumerate(tqdm(data_loader)):\n",
    "        try:\n",
    "            data, mask, ordered_mask, factors = data\n",
    "        except:\n",
    "            data, mask, ordered_mask, factors, _, _ = data\n",
    "        assert not torch.isnan(data).any()\n",
    "    #         print(data, mask)\n",
    "        assert not torch.logical_and(data <= 0, ~mask).any(), torch.min(data * mask)\n",
    "\n",
    "        C_train = data.transpose_(0, 1).float().to(device)[:-1]\n",
    "\n",
    "        C_mask = mask.float().to(device).transpose_(0, 1)[:-1]\n",
    "        C_ordered_mask = ordered_mask.float().to(device).transpose_(0, 1)[:-1]\n",
    "\n",
    "        factors = factors.transpose_(0, 1).float().to(device)[1:]\n",
    "\n",
    "        train_input = torch.cat([C_train, C_mask, factors], axis=2)\n",
    "\n",
    "\n",
    "        if train_input.shape[1] == 10:\n",
    "            alpha_pred, beta_pred, hidden_out = model(train_input)\n",
    "\n",
    "            model_input = torch.cat([hidden_out[:-1].detach(), C_train[1:]], axis=2)\n",
    "            batch_size, batch_length, dim = model_input.shape\n",
    "            model_input = model_input.reshape(batch_size * batch_length, dim)\n",
    "\n",
    "            C_ordered_mask_reshape = C_ordered_mask[1:].reshape(batch_size * batch_length, 45)\n",
    "            C_mask_reshape = C_ordered_mask[1:].reshape(batch_size * batch_length, 45)\n",
    "            C_train_reshape = C_train[1:].reshape(batch_size * batch_length, 45)\n",
    "\n",
    "            pred = ar_model.impute(model_input)\n",
    "            preds.append(pred.detach().cpu().numpy())\n",
    "            gts.append(C_train_reshape.detach().cpu().numpy())\n",
    "            train_masks.append(C_mask_reshape.detach().cpu().numpy())\n",
    "\n",
    "    preds = np.concatenate(preds, axis=0)\n",
    "    gts = np.concatenate(gts, axis=0)\n",
    "    train_masks = np.concatenate(train_masks, axis=0)\n",
    "    gts[train_masks == 1] = np.nan\n",
    "    mse = np.nanmean((preds - gts)**2, axis=0)\n",
    "    return list(zip(chars, np.sqrt(mse)))\n",
    "\n",
    "def eval_model_oos(model, ar_model, data_loader):\n",
    "    preds = []\n",
    "    gts = []\n",
    "    train_masks = []\n",
    "    for i, data in enumerate(tqdm(data_loader)):\n",
    "        data, mask, ordered_mask, factors, oos_data, oos_mask = data\n",
    "        assert not torch.isnan(data).any()\n",
    "    #         print(data, mask)\n",
    "        assert not torch.logical_and(data <= 0, ~mask).any(), torch.min(data * mask)\n",
    "\n",
    "        C_train = data.transpose_(0, 1).float().to(device)[:-1]\n",
    "        C_test = oos_data.transpose_(0, 1).float().to(device)[:-1]\n",
    "        C_mask = mask.float().to(device).transpose_(0, 1)[:-1]\n",
    "        C_test_mask = oos_mask.float().to(device).transpose_(0, 1)[:-1]\n",
    "        C_ordered_mask = ordered_mask.float().to(device).transpose_(0, 1)[:-1]\n",
    "\n",
    "        factors = factors.transpose_(0, 1).float().to(device)[1:]\n",
    "\n",
    "        train_input = torch.cat([C_train, C_mask, factors], axis=2)\n",
    "\n",
    "\n",
    "        if train_input.shape[1] == 10:\n",
    "            alpha_pred, beta_pred, hidden_out = model(train_input)\n",
    "\n",
    "            model_input = torch.cat([hidden_out[:-1].detach(), C_train[1:]], axis=2)\n",
    "            batch_size, batch_length, dim = model_input.shape\n",
    "            model_input = model_input.reshape(batch_size * batch_length, dim)\n",
    "\n",
    "            C_ordered_mask_reshape = C_ordered_mask[1:].reshape(batch_size * batch_length, 45)\n",
    "            C_mask_reshape = C_ordered_mask[1:].reshape(batch_size * batch_length, 45)\n",
    "            C_test_mask_reshape = C_test_mask[1:].reshape(batch_size * batch_length, 45)\n",
    "            \n",
    "            C_train_reshape = C_train[1:].reshape(batch_size * batch_length, 45)\n",
    "            C_test_reshape = C_test[1:].reshape(batch_size * batch_length, 45)\n",
    "\n",
    "            pred = ar_model.impute(model_input)\n",
    "            preds.append(pred.detach().cpu().numpy())\n",
    "            gts.append(C_test_reshape.detach().cpu().numpy())\n",
    "            train_masks.append(C_test_mask_reshape.detach().cpu().numpy())\n",
    "#             print(preds[-1][train_masks[-1] ==1], gts[-1][train_masks[-1] ==1])\n",
    "#             print()\n",
    "            \n",
    "    preds = np.concatenate(preds, axis=0)\n",
    "    gts = np.concatenate(gts, axis=0)\n",
    "    train_masks = np.concatenate(train_masks, axis=0)\n",
    "    gts[train_masks != 1] = np.nan\n",
    "    mse = np.nanmean((preds - gts)**2, axis=0)\n",
    "    return list(zip(chars, np.sqrt(mse)))\n",
    "\n",
    "\n",
    "def eval_ts_model_is(model, data_loader):\n",
    "    preds = []\n",
    "    gts = []\n",
    "    train_masks = []\n",
    "    for i, data in enumerate(tqdm(data_loader)):\n",
    "        try:\n",
    "            data, mask, ordered_mask, factors = data\n",
    "        except:\n",
    "            data, mask, ordered_mask, factors, oos_data, oos_mask  = data\n",
    "        assert not torch.isnan(data).any()\n",
    "    #         assert not (data <= 0).any(), torch.min(data)\n",
    "    #         print(data.shape)\n",
    "        C_train = data.transpose_(0, 1).float().to(device)[:-1]\n",
    "\n",
    "        C_mask = mask.float().to(device).transpose_(0, 1)[:-1]\n",
    "        C_ordered_mask = ordered_mask.float().to(device).transpose_(0, 1)[:-1]\n",
    "\n",
    "        factors = factors.transpose_(0, 1).float().to(device)[1:]\n",
    "\n",
    "        train_input = torch.cat([C_train, C_mask, factors], axis=2)       \n",
    "        if train_input.shape[1] == 10:\n",
    "            alpha_pred, beta_pred,_ = model(train_input)\n",
    "\n",
    "            pred = alpha_pred / (alpha_pred + beta_pred)\n",
    "            preds.append(pred.detach().cpu().numpy())\n",
    "            gts.append(C_train.detach().cpu().numpy())\n",
    "            train_masks.append(C_mask.detach().cpu().numpy())\n",
    "\n",
    "    preds = np.concatenate(preds, axis=0)\n",
    "    gts = np.concatenate(gts, axis=0)\n",
    "    train_masks = np.concatenate(train_masks, axis=0)\n",
    "    gts[train_masks == 1] = np.nan\n",
    "\n",
    "    mse = np.nanmean((preds - gts)**2, axis=(0,1))\n",
    "    return list(zip(chars[ordering], np.sqrt(mse))), np.mean(np.sqrt(mse))\n",
    "\n",
    "def eval_ts_model_oos(model, data_loader):\n",
    "    preds = []\n",
    "    gts = []\n",
    "    train_masks = []\n",
    "    for i, data in enumerate(tqdm(data_loader)):\n",
    "        data, mask, ordered_mask, factors, oos_data, oos_mask  = data\n",
    "        assert not torch.isnan(data).any()\n",
    "    #         assert not (data <= 0).any(), torch.min(data)\n",
    "    #         print(data.shape)\n",
    "        C_train = data.transpose_(0, 1).float().to(device)[:-1]\n",
    "        C_test = oos_data.transpose_(0, 1).float().to(device)[:-1]\n",
    "        C_mask = mask.float().to(device).transpose_(0, 1)[:-1]\n",
    "        C_ordered_mask = ordered_mask.float().to(device).transpose_(0, 1)[:-1]\n",
    "        C_test_mask = oos_mask.float().to(device).transpose_(0, 1)[:-1]\n",
    "\n",
    "        factors = factors.transpose_(0, 1).float().to(device)[1:]\n",
    "\n",
    "        train_input = torch.cat([C_train, C_mask, factors], axis=2)       \n",
    "        if train_input.shape[1] == 10:\n",
    "            alpha_pred, beta_pred,_ = model(train_input)\n",
    "\n",
    "            pred = alpha_pred / (alpha_pred + beta_pred)\n",
    "            preds.append(pred.detach().cpu().numpy())\n",
    "            gts.append(C_test.detach().cpu().numpy())\n",
    "            train_masks.append(C_test_mask.detach().cpu().numpy())\n",
    "\n",
    "    preds = np.concatenate(preds, axis=0)\n",
    "    gts = np.concatenate(gts, axis=0)\n",
    "    train_masks = np.concatenate(train_masks, axis=0)\n",
    "    gts[train_masks != 1] = np.nan\n",
    "\n",
    "    mse = np.nanmean((preds - gts)**2, axis=(0,1))\n",
    "    return list(zip(chars, np.sqrt(mse))), np.mean(np.sqrt(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e56f28ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e204f7e5641a4bf1a60bd439e672b5f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/147 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[('PM', 0.27808625),\n",
       " ('OP', 0.29084486),\n",
       " ('R12_2', 0.28621244),\n",
       " ('AC', 0.28896803),\n",
       " ('FC2Y', 0.27615285),\n",
       " ('DPI2A', 0.27720097),\n",
       " ('Q', 0.27766284),\n",
       " ('R60_13', 0.288725),\n",
       " ('HIGH52', 0.283587),\n",
       " ('RNA', 0.29168615),\n",
       " ('R12_7', 0.2927738),\n",
       " ('B2M', 0.2906263),\n",
       " ('ROA', 0.2898613),\n",
       " ('SGA2S', 0.29056242),\n",
       " ('RVAR', 0.28501433),\n",
       " ('SUV', 0.2836168),\n",
       " ('D2P', 0.27184334),\n",
       " ('ME', 0.2840959),\n",
       " ('NOA', 0.2844836),\n",
       " ('LEV', 0.28924266),\n",
       " ('ATO', 0.28487954),\n",
       " ('CTO', 0.28909397),\n",
       " ('IdioVol', 0.2876099),\n",
       " ('TURN', 0.28521696),\n",
       " ('OL', 0.28795233),\n",
       " ('D2A', 0.28402916),\n",
       " ('CF2P', 0.28753668),\n",
       " ('SPREAD', 0.29405928),\n",
       " ('PROF', 0.29036552),\n",
       " ('BETA_m', 0.28841734),\n",
       " ('R36_13', 0.2849772),\n",
       " ('BETA_d', 0.286386),\n",
       " ('ROE', 0.28672278),\n",
       " ('PCM', 0.29475588),\n",
       " ('A2ME', 0.28921622),\n",
       " ('VAR', 0.29406393),\n",
       " ('NI', 0.28846923),\n",
       " ('E2P', 0.29119375),\n",
       " ('CF2B', 0.28684208),\n",
       " ('OA', 0.28919074),\n",
       " ('C2A', 0.2905262),\n",
       " ('R2_1', 0.28963268),\n",
       " ('AT', 0.28462616),\n",
       " ('INV', 0.2854173),\n",
       " ('S2P', 0.2942026)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487d94de",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "gts = []\n",
    "train_masks = []\n",
    "for i, data in enumerate(tqdm(train_data_loader)):\n",
    "    data, mask, ordered_mask, factors = data\n",
    "    assert not torch.isnan(data).any()\n",
    "#         print(data, mask)\n",
    "    assert not torch.logical_and(data <= 0, ~mask).any(), torch.min(data * mask)\n",
    "\n",
    "    C_train = data.transpose_(0, 1).float().to(device)[:-1]\n",
    "        \n",
    "    C_mask = mask.float().to(device).transpose_(0, 1)[:-1]\n",
    "    C_ordered_mask = ordered_mask.float().to(device).transpose_(0, 1)[:-1]\n",
    "\n",
    "    factors = factors.transpose_(0, 1).float().to(device)[1:]\n",
    "\n",
    "    train_input = torch.cat([C_train, C_mask, factors], axis=2)\n",
    "\n",
    "\n",
    "    if train_input.shape[1] == 10:\n",
    "        alpha_pred, beta_pred, hidden_out = model(train_input)\n",
    "\n",
    "        model_input = torch.cat([hidden_out[:-1].detach(), C_train[1:]], axis=2)\n",
    "        batch_size, batch_length, dim = model_input.shape\n",
    "        model_input = model_input.reshape(batch_size * batch_length, dim)\n",
    "\n",
    "        C_mask_reshape = C_ordered_mask[1:].reshape(batch_size * batch_length, 45)\n",
    "        C_ordered_mask_reshape = C_ordered_mask[1:].reshape(batch_size * batch_length, 45)\n",
    "        C_train_reshape = C_train[1:].reshape(batch_size * batch_length, 45)\n",
    "\n",
    "        alphas_pred, betas_pred = ar_model(model_input)\n",
    "        pred = alphas_pred / (alphas_pred + betas_pred)\n",
    "        preds.append(pred.detach().cpu().numpy())\n",
    "        gts.append(C_train_reshape.detach().cpu().numpy())\n",
    "        train_masks.append(C_ordered_mask_reshape.detach().cpu().numpy())\n",
    "\n",
    "preds = np.concatenate(preds, axis=0)\n",
    "gts = np.concatenate(gts, axis=0)\n",
    "train_masks = np.concatenate(train_masks, axis=0)\n",
    "gts[train_masks == 1] = np.nan\n",
    "mse = np.nanmean((preds - gts)**2, axis=0)\n",
    "list(zip(chars[ordering], np.sqrt(mse)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
